{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ASR Assignment 2022-23\n",
    "\n",
    "This notebook has been provided as a template to get you started on the assignment.  Feel free to use it for your development, or do your development directly in Python.\n",
    "\n",
    "You can find a full description of the assignment [here](http://www.inf.ed.ac.uk/teaching/courses/asr/2022-23/coursework.pdf).\n",
    "\n",
    "You are provided with two Python modules `observation_model.py` and `wer.py`.  The first was described in [Lab 3](https://github.com/ZhaoZeyu1995/asr_labs/blob/master/asr_lab3_4.ipynb).  The second can be used to compute the number of substitution, deletion and insertion errors between ASR output and a reference text.\n",
    "\n",
    "It can be used as follows:\n",
    "\n",
    "```python\n",
    "import wer\n",
    "\n",
    "my_refence = 'A B C'\n",
    "my_output = 'A C C D'\n",
    "\n",
    "wer.compute_alignment_errors(my_reference, my_output)\n",
    "```\n",
    "\n",
    "This produces a tuple $(s,d,i)$ giving counts of substitution,\n",
    "deletion and insertion errors respectively - in this example (1, 0, 1).  The function accepts either two strings, as in the example above, or two lists.  Matching is case sensitive.\n",
    "\n",
    "## Template code\n",
    "\n",
    "Assuming that you have already made a function to generate an WFST, `create_wfst()` and a decoder class, `MyViterbiDecoder`, you can perform recognition on all the audio files as follows:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2282172\n",
    "s2473164 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append('/afs/inf.ed.ac.uk/user/s22/s2282172/.conda/envs/asr_env/lib/python3.7/site-packages') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math \n",
    "import openfst_python as fst \n",
    "import glob\n",
    "import time \n",
    "import os \n",
    "import numpy as np \n",
    "from copy import deepcopy \n",
    "from collections import defaultdict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyViterbiDecoder:\n",
    "    \n",
    "    NLL_ZERO = 1e10  # define a constant representing -log(0).  This is really infinite, but approximate\n",
    "                     # it here with a very large number\n",
    "    \n",
    "    def __init__(self, f, audio_file_name, beam_width=None, beam_size=float('inf'), lm_look_ahead=False):\n",
    "        \"\"\"Set up the decoder class with an audio file and WFST f\n",
    "        \"\"\"\n",
    "        self.om = observation_model.ObservationModel()\n",
    "        self.f = f\n",
    "        self.beam_width = beam_width \n",
    "        self.beam_size = beam_size\n",
    "        self.lm_look_ahead = lm_look_ahead \n",
    "        \n",
    "        if self.beam_width is not None and self.beam_size != float('inf'):\n",
    "            raise ValueError('Only one of beam width and beam size can be used.') \n",
    "        \n",
    "        if audio_file_name:\n",
    "            self.om.load_audio(audio_file_name)\n",
    "        else:\n",
    "            self.om.load_dummy_audio()\n",
    "        \n",
    "        self.initialise_decoding()\n",
    "\n",
    "        \n",
    "    def initialise_decoding(self):\n",
    "        \"\"\"set up the values for V_j(0) (as negative log-likelihoods)\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        self.V = []   # stores likelihood along best path reaching state j\n",
    "        self.B = []   # stores identity of best previous state reaching state j\n",
    "        self.W = []   # stores output labels sequence along arc reaching j - this removes need for \n",
    "                      # extra code to read the output sequence along the best path\n",
    "        self.computations = 0 \n",
    "        \n",
    "        for t in range(self.om.observation_length()+1):\n",
    "            self.V.append([self.NLL_ZERO]*self.f.num_states())\n",
    "            self.B.append([-1]*self.f.num_states())\n",
    "            self.W.append([[] for i in range(self.f.num_states())])  #  multiplying the empty list doesn't make multiple\n",
    "        \n",
    "        # The above code means that self.V[t][j] for t = 0, ... T gives the Viterbi cost\n",
    "        # of state j, time t (in negative log-likelihood form)\n",
    "        # Initialising the costs to NLL_ZERO effectively means zero probability    \n",
    "        \n",
    "        # give the WFST start state a probability of 1.0   (NLL = 0.0)\n",
    "        self.V[0][self.f.start()] = 0.0\n",
    "        \n",
    "        # some WFSTs might have arcs with epsilon on the input (you might have already created \n",
    "        # examples of these in earlier labs) these correspond to non-emitting states, \n",
    "        # which means that we need to process them without stepping forward in time.  \n",
    "        # Don't worry too much about this!  \n",
    "        self.traverse_epsilon_arcs(0)        \n",
    "        \n",
    "    def traverse_epsilon_arcs(self, t):\n",
    "        \"\"\"Traverse arcs with <eps> on the input at time t\n",
    "        \n",
    "        These correspond to transitions that don't emit an observation\n",
    "        \n",
    "        We've implemented this function for you as it's slightly trickier than\n",
    "        the normal case.  You might like to look at it to see what's going on, but\n",
    "        don't worry if you can't fully follow it.\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        states_to_traverse = list(self.f.states()) # traverse all states\n",
    "        while states_to_traverse:\n",
    "            \n",
    "            # Set i to the ID of the current state, the first \n",
    "            # item in the list (and remove it from the list)\n",
    "            i = states_to_traverse.pop(0)   \n",
    "        \n",
    "            # don't bother traversing states which have zero probability\n",
    "            if self.V[t][i] == self.NLL_ZERO:\n",
    "                    continue\n",
    "        \n",
    "            for arc in self.f.arcs(i):\n",
    "                \n",
    "                if arc.ilabel == 0:     # if <eps> transition\n",
    "                  \n",
    "                    j = arc.nextstate   # ID of next state  \n",
    "                \n",
    "                    if self.V[t][j] > self.V[t][i] + float(arc.weight):\n",
    "                        \n",
    "                        # this means we've found a lower-cost path to\n",
    "                        # state j at time t.  We might need to add it\n",
    "                        # back to the processing queue.\n",
    "                        self.V[t][j] = self.V[t][i] + float(arc.weight)\n",
    "                        \n",
    "                        # save backtrace information.  In the case of an epsilon transition, \n",
    "                        # we save the identity of the best state at t-1.  This means we may not\n",
    "                        # be able to fully recover the best path, but to do otherwise would\n",
    "                        # require a more complicated way of storing backtrace information\n",
    "                        self.B[t][j] = self.B[t][i] \n",
    "                        \n",
    "                        # and save the output labels encountered - this is a list, because\n",
    "                        # there could be multiple output labels (in the case of <eps> arcs)\n",
    "                        if arc.olabel != 0:\n",
    "                            self.W[t][j] = self.W[t][i] + [arc.olabel]\n",
    "                        else:\n",
    "                            self.W[t][j] = self.W[t][i]\n",
    "                        \n",
    "                        if j not in states_to_traverse:\n",
    "                            states_to_traverse.append(j)\n",
    "\n",
    "    \n",
    "    def forward_step(self, t):\n",
    "          \n",
    "        for i in self.f.states():\n",
    "            \n",
    "            if not self.V[t-1][i] == self.NLL_ZERO:   # no point in propagating states with zero probability\n",
    "                \n",
    "                for arc in self.f.arcs(i):\n",
    "                    \n",
    "                    if arc.ilabel != 0: # <eps> transitions don't emit an observation\n",
    "                        j = arc.nextstate\n",
    "                        tp = float(arc.weight)  # transition prob\n",
    "                        ep = -self.om.log_observation_probability(self.f.input_symbols().find(arc.ilabel), t)  # emission negative log prob\n",
    "                        prob = tp + ep + self.V[t-1][i] # they're logs \n",
    "                        if self.lm_look_ahead == True:\n",
    "                            prob = prob - math.log(unigram_lm_look_ahead_prob[j]) \n",
    "                        self.computations += 1 \n",
    "                        if prob < self.V[t][j]:\n",
    "                            self.V[t][j] = prob\n",
    "                            self.B[t][j] = i\n",
    "                            \n",
    "                            # store the output labels encountered too\n",
    "                            if arc.olabel !=0:\n",
    "                                self.W[t][j] = [arc.olabel]\n",
    "                            else:\n",
    "                                self.W[t][j] = []\n",
    "        \n",
    "        if self.beam_width is not None:\n",
    "            min_vt_value = min(self.V[t])\n",
    "            for j in range(len(self.V[t])):\n",
    "                if self.V[t][j] > -math.log(self.beam_width) + min_vt_value:\n",
    "                    self.V[t][j] = self.NLL_ZERO \n",
    "        \n",
    "        if self.beam_size != float('inf'): \n",
    "            vt_value = sorted(self.V[t])\n",
    "            beam_size = min(self.beam_size, len(self.V[t]))\n",
    "            thershold = vt_value[self.beam_size - 1]\n",
    "            for j in range(len(self.V[t])):\n",
    "                if self.V[t][j] > thershold:\n",
    "                    self.V[t][j] = self.NLL_ZERO \n",
    "                            \n",
    "    \n",
    "    def finalise_decoding(self):\n",
    "        \"\"\" this incorporates the probability of terminating at each state\n",
    "        \"\"\"\n",
    "        \n",
    "        for state in self.f.states():\n",
    "            final_weight = float(self.f.final(state))\n",
    "            if self.V[-1][state] != self.NLL_ZERO:\n",
    "                if final_weight == math.inf:\n",
    "                    self.V[-1][state] = self.NLL_ZERO  # effectively says that we can't end in this state\n",
    "                else:\n",
    "                    self.V[-1][state] += final_weight\n",
    "                    \n",
    "        # get a list of all states where there was a path ending with non-zero probability\n",
    "        finished = [x for x in self.V[-1] if x < self.NLL_ZERO]\n",
    "        if not finished:  # if empty\n",
    "            print(\"No path got to the end of the observations.\")\n",
    "        \n",
    "        \n",
    "    def decode(self):\n",
    "        self.initialise_decoding()\n",
    "        t = 1\n",
    "        while t <= self.om.observation_length():\n",
    "            self.forward_step(t)\n",
    "            self.traverse_epsilon_arcs(t)\n",
    "            t += 1\n",
    "        self.finalise_decoding()\n",
    "        return self.computations \n",
    "    \n",
    "    def backtrace(self):\n",
    "        \n",
    "        best_final_state = self.V[-1].index(min(self.V[-1])) # argmin\n",
    "        best_state_sequence = [best_final_state]\n",
    "        best_out_sequence = []\n",
    "        \n",
    "        t = self.om.observation_length()   # ie T\n",
    "        j = best_final_state\n",
    "        \n",
    "        while t >= 0:\n",
    "            i = self.B[t][j]\n",
    "            best_state_sequence.append(i)\n",
    "            best_out_sequence = self.W[t][j] + best_out_sequence  # computer scientists might like\n",
    "                                                                                # to make this more efficient!\n",
    "\n",
    "            # continue the backtrace at state i, time t-1\n",
    "            j = i  \n",
    "            t-=1\n",
    "            \n",
    "        best_state_sequence.reverse()\n",
    "        \n",
    "        # convert the best output sequence from FST integer labels into strings\n",
    "        # best_out_sequence = ' '.join([ self.f.output_symbols().find(label) for label in best_out_sequence]) \n",
    "        out_sequence = []\n",
    "        for label in best_out_sequence:\n",
    "            out_sequence.append(self.f.output_symbols().find(label))\n",
    "            \n",
    "        \n",
    "        # return (best_state_sequence, best_out_sequence)\n",
    "        return (best_state_sequence, out_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_lexicon(lex_file):\n",
    "    \"\"\"\n",
    "    Parse the lexicon file and return it in dictionary form.\n",
    "    \n",
    "    Args:\n",
    "        lex_file (str): filename of lexicon file with structure '<word> <phone1> <phone2>...'\n",
    "                        eg. peppers p eh p er z\n",
    "\n",
    "    Returns:\n",
    "        lex (dict): dictionary mapping words to list of phones\n",
    "    \"\"\"\n",
    "    \n",
    "    lex = {}  # create a dictionary for the lexicon entries (this could be a problem with larger lexica)\n",
    "    with open(lex_file, 'r') as f:\n",
    "        for line in f:\n",
    "            line = line.split()  # split at each space\n",
    "            lex[line[0]] = line[1:]  # first field the word, the rest is the phones\n",
    "    return lex\n",
    "\n",
    "def generate_symbol_tables(lexicon, n=3):\n",
    "    '''\n",
    "    Return word, phone and state symbol tables based on the supplied lexicon\n",
    "        \n",
    "    Args:\n",
    "        lexicon (dict): lexicon to use, created from the parse_lexicon() function\n",
    "        n (int): number of states for each phone HMM\n",
    "        \n",
    "    Returns:\n",
    "        word_table (fst.SymbolTable): table of words\n",
    "        phone_table (fst.SymbolTable): table of phones\n",
    "        state_table (fst.SymbolTable): table of HMM phone-state IDs\n",
    "    '''\n",
    "    \n",
    "    state_table = fst.SymbolTable()\n",
    "    phone_table = fst.SymbolTable()\n",
    "    word_table = fst.SymbolTable()\n",
    "    \n",
    "    # add empty <eps> symbol to all tables\n",
    "    state_table.add_symbol('<eps>')\n",
    "    phone_table.add_symbol('<eps>')\n",
    "    word_table.add_symbol('<eps>')\n",
    "    \n",
    "    for word, phones  in lexicon.items():\n",
    "        \n",
    "        word_table.add_symbol(word)\n",
    "        \n",
    "        for p in phones: # for each phone\n",
    "            \n",
    "            phone_table.add_symbol(p)\n",
    "            for i in range(1,n+1): # for each state 1 to n\n",
    "                state_table.add_symbol('{}_{}'.format(p, i))\n",
    "            \n",
    "    return word_table, phone_table, state_table\n",
    "\n",
    "\n",
    "# call these two functions\n",
    "lex = parse_lexicon('lexicon.txt')\n",
    "word_table, phone_table, state_table = generate_symbol_tables(lex)\n",
    "'''\n",
    "phones_words_dict = {}\n",
    "for word, phones in lex.items():\n",
    "    phones_words_dict[tuple(phones)] = word \n",
    "'''\n",
    "\n",
    "def generate_phone_wfst(f, start_state, phone, n, output_phone=False):\n",
    "    \"\"\"\n",
    "    Generate a WFST representating an n-state left-to-right phone HMM\n",
    "    \n",
    "    Args:\n",
    "        f (fst.Fst()): an FST object, assumed to exist already\n",
    "        start_state (int): the index of the first state, assmed to exist already\n",
    "        phone (str): the phone label \n",
    "        n (int): number of states for each phone HMM\n",
    "        \n",
    "    Returns:\n",
    "        the final state of the FST\n",
    "    \"\"\"\n",
    "    \n",
    "    current_state = start_state\n",
    "    \n",
    "    for i in range(1, n+1):\n",
    "        \n",
    "        in_label = state_table.find('{}_{}'.format(phone, i))\n",
    "        \n",
    "        sl_weight = fst.Weight('log', -math.log(0.1))  # weight for self-loop\n",
    "        # self-loop back to current state\n",
    "        f.add_arc(current_state, fst.Arc(in_label, 0, sl_weight, current_state))\n",
    "        # f.add_arc(current_state, fst.Arc(in_label, 0, None, current_state))\n",
    "        \n",
    "        # transition to next state\n",
    "        \n",
    "        # we want to output the phone label on the final state\n",
    "        # note: if outputting words instead this code should be modified\n",
    "        \n",
    "        if output_phone: \n",
    "            if i == n:\n",
    "                out_label = phone_table.find(phone)\n",
    "            else:\n",
    "                out_label = 0   # output empty <eps> label\n",
    "        \n",
    "        else: \n",
    "            out_label = 0 \n",
    "            \n",
    "        next_state = f.add_state()\n",
    "        next_weight = fst.Weight('log', -math.log(0.9)) # weight to next state\n",
    "        f.add_arc(current_state, fst.Arc(in_label, out_label, next_weight, next_state)) \n",
    "        # f.add_arc(current_state, fst.Arc(in_label, out_label, None, next_state))\n",
    "       \n",
    "        current_state = next_state\n",
    "        \n",
    "    return current_state\n",
    "\n",
    "def generate_word_wfst(word):\n",
    "    \"\"\" Generate a WFST for any word in the lexicon, composed of 3-state phone WFSTs.\n",
    "        This will currently output word labels.  \n",
    "        Exercise: could you modify this function and the one above to output a single phone label instead?\n",
    "    \n",
    "    Args:\n",
    "        word (str): the word to generate\n",
    "        \n",
    "    Returns:\n",
    "        the constructed WFST\n",
    "    \n",
    "    \"\"\"\n",
    "    f = fst.Fst('log')\n",
    "    \n",
    "    # create the start state\n",
    "    start_state = f.add_state()\n",
    "    f.set_start(start_state)\n",
    "    \n",
    "    current_state = start_state\n",
    "    \n",
    "    # iterate over all the phones in the word\n",
    "    for phone in lex[word]:   # will raise an exception if word is not in the lexicon\n",
    "        \n",
    "        current_state = generate_phone_wfst(f, current_state, phone, 3)\n",
    "    \n",
    "        # note: new current_state is now set to the final state of the previous phone WFST\n",
    "        \n",
    "    f.set_final(current_state)\n",
    "    \n",
    "    return f\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_state_dict = defaultdict(list)\n",
    "# word_state_dict contains word and its correnponding states, including silence states. \n",
    "for word, phones in lex.items():\n",
    "    for phone in phones:\n",
    "        for i in range(1, 4):\n",
    "            word_state_dict[word].append('{}_{}'.format(phone, i))\n",
    "    for j in range(1, 6):\n",
    "        word_state_dict[word].append('sil_{}'.format(j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_word_sequence_wfst(n=3):\n",
    "    \"\"\" generate a HMM to recognise any single word sequence for words in the lexicon\n",
    "    \n",
    "    Args:\n",
    "        n (int): states per phone HMM\n",
    "\n",
    "    Returns:\n",
    "        the constructed WFST\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    f = fst.Fst('log')\n",
    "    \n",
    "    # create a single start state\n",
    "    start_state = f.add_state()\n",
    "    f.set_start(start_state)\n",
    "    \n",
    "    for word, phones in lex.items():\n",
    "        current_state = f.add_state()\n",
    "        # The transition probability to each is equal. \n",
    "        f.add_arc(start_state, fst.Arc(0, word_table.find(word),\\\n",
    "                                       fst.Weight('log', -math.log(1 / len(lex.keys()))), current_state)) \n",
    "        \n",
    "        for phone in phones: \n",
    "            current_state = generate_phone_wfst(f, current_state, phone, n)\n",
    "        # note: new current_state is now set to the final state of the previous phone WFST\n",
    "        \n",
    "        f.set_final(current_state)\n",
    "        f.add_arc(current_state, fst.Arc(0, 0, fst.Weight('log', -math.log(1)), start_state))\n",
    "        \n",
    "    return f "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phone_index_dict = {}\n",
    "max_word_phone_length = 0\n",
    "for phones in lex.values():\n",
    "    max_word_phone_length = max(max_word_phone_length, len(phones))\n",
    "    for phone in phones:\n",
    "        phone_index_dict[phone] = phone_table.find(phone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_sil_table = deepcopy(state_table)\n",
    "# state_sil_table contains all the states from the state_table and silence states. \n",
    "for i in range(1, 6):\n",
    "    state_sil_table.add_symbol('sil_{}'.format(i)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_index_dict = {}\n",
    "max_word_state_length = 0\n",
    "for states in word_state_dict.values():\n",
    "    max_word_state_length = max(max_word_state_length, len(states))\n",
    "    for state in states:\n",
    "        state_index_dict[state] = state_sil_table.find(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_tree_lexicon(lex):\n",
    "    \n",
    "    '''\n",
    "    Generate tree structure lexicon. \n",
    "    '''\n",
    "    \n",
    "    words_phones_array = np.zeros((len(lex.keys()), max_word_phone_length + 1))\n",
    "    # words_phones_array contains the indexes of all the phones for each word in the lexicon, each row \n",
    "    # represents one word in the lexicon. \n",
    "    states_array = np.zeros((words_phones_array.shape))\n",
    "    # states_array contains the indexes of the states we have added. \n",
    "    word_list = sorted(lex.keys())\n",
    "    for i in range(len(word_list)):\n",
    "        for j in range(len(lex[word_list[i]])):\n",
    "            words_phones_array[i, j] = phone_index_dict[lex[word_list[i]][j]]\n",
    "    final_states = []\n",
    "    \n",
    "    f = fst.Fst('log')\n",
    "    start_state = f.add_state()\n",
    "    f.set_start(start_state) \n",
    "    \n",
    "    for i in range(words_phones_array.shape[0]):\n",
    "        add_state = True \n",
    "        for index, phones in enumerate(words_phones_array[0:i, 0]):\n",
    "            if words_phones_array[i, 0] == phones:\n",
    "                # If the previous words have the same phone at this time step. \n",
    "                add_state = False\n",
    "                states_array[i, 0] = states_array[index, 0]\n",
    "                break \n",
    "        \n",
    "        if add_state:\n",
    "            if words_phones_array[i, 1] == 0:\n",
    "                # If the word does not have phone at next time step. \n",
    "                word_final_state = f.add_state()\n",
    "                f.set_final(word_final_state) \n",
    "                final_states.append(word_final_state)\n",
    "                states_array[i, 0] = word_final_state \n",
    "                f.add_arc(start_state, fst.Arc(words_phones_array[i, 0], \\\n",
    "                              word_table.find(word_list[i]), fst.Weight('log', -math.log(1)), word_final_state)) \n",
    "            else:\n",
    "                state = f.add_state()\n",
    "                states_array[i, 0] = state\n",
    "                f.add_arc(start_state, fst.Arc(words_phones_array[i, 0], 0, \\\n",
    "                                                 fst.Weight('log', -math.log(1)), state)) \n",
    "    \n",
    "    for j in range(1, words_phones_array.shape[1] - 1):\n",
    "        for i in range(words_phones_array.shape[0]):\n",
    "            if words_phones_array[i, j] != 0:\n",
    "                # If the word has phone at this time step. \n",
    "                add_state = True \n",
    "                for index, array in enumerate(words_phones_array[0:i, 0:j+1]):\n",
    "                    if np.allclose(words_phones_array[i, 0:j+1], array):\n",
    "                        # If the previous words have the same phones at all the previous time steps \n",
    "                        # and this time step. \n",
    "                        add_state = False\n",
    "                        states_array[i, 0:j+1] = states_array[index, 0:j+1]\n",
    "                        break\n",
    "                        \n",
    "                if add_state: \n",
    "                    if words_phones_array[i, j+1] == 0:\n",
    "                        # If the word has phone at next time step. \n",
    "                        word_final_state = f.add_state()\n",
    "                        f.set_final(word_final_state)\n",
    "                        final_states.append(word_final_state)\n",
    "                        states_array[i, j] = word_final_state\n",
    "                        f.add_arc(states_array[i, j-1], fst.Arc(words_phones_array[i, j], \\\n",
    "                                word_table.find(word_list[i]), fst.Weight('log', -math.log(1)), word_final_state))\n",
    "                    else:\n",
    "                        state = f.add_state()\n",
    "                        states_array[i, j] = state\n",
    "                        f.add_arc(states_array[i, j-1], fst.Arc(words_phones_array[i, j], 0, \\\n",
    "                                                               fst.Weight('log', -math.log(1)), state)) \n",
    "    for state in final_states:\n",
    "        f.add_arc(state, fst.Arc(0, 0, fst.Weight('log', -math.log(1)), start_state)) \n",
    "    \n",
    "    return f, words_phones_array, states_array "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_lexicon, words_phones_array, states_array = generate_tree_lexicon(lex)\n",
    "words_phones_array, states_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_lexicon, _, _ = generate_tree_lexicon(lex)\n",
    "tree_lexicon.set_input_symbols(phone_table)\n",
    "tree_lexicon.set_output_symbols(word_table)\n",
    "from subprocess import check_call\n",
    "from IPython.display import Image \n",
    "tree_lexicon.draw('tmp.dot', portrait=True)\n",
    "check_call(['dot','-Tpng','-Gdpi=200','tmp.dot','-o','tmp.png'])\n",
    "Image(filename='tmp.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_tree_wfst(word_state_dict):\n",
    "    \n",
    "    '''\n",
    "    Generate tree structure wfst to recognize a sequence of words. \n",
    "    '''\n",
    "    \n",
    "    # words_phones_array = np.zeros((len(lex.keys()), max_word_phone_length + 1))\n",
    "    words_states_array = np.zeros((len(word_state_dict.keys()), max_word_state_length + 1))\n",
    "    # words_states_array contains the indexes of all the states for each word in the lexicon, each row \n",
    "    # represents one word in the lexicon. \n",
    "    states_array = np.zeros((words_states_array.shape))\n",
    "    # states_array contains the indexes of the states we have added. \n",
    "    word_list = sorted(word_state_dict.keys())\n",
    "    for i in range(len(word_list)):\n",
    "        for j in range(len(word_state_dict[word_list[i]])):\n",
    "            # words_phones_array[i, j] = phone_index_dict[lex[word_list[i]][j]]\n",
    "            words_states_array[i, j] = state_index_dict[word_state_dict[word_list[i]][j]]\n",
    "    final_states = []\n",
    "    word_final_list = []\n",
    "    \n",
    "    f = fst.Fst('log')\n",
    "    start_state = f.add_state()\n",
    "    f.set_start(start_state) \n",
    "    \n",
    "    for i in range(words_states_array.shape[0]):\n",
    "        add_state = True \n",
    "        for index, states in enumerate(words_states_array[0:i, 0]):\n",
    "            if words_states_array[i, 0] == states:\n",
    "                # If the previous words have the same state at this time step. \n",
    "                add_state = False\n",
    "                states_array[i, 0] = states_array[index, 0]\n",
    "                break \n",
    "        \n",
    "        if add_state:\n",
    "            if words_states_array[i, 1] == 0:\n",
    "                # If the word does not have state at next time step. \n",
    "                word_final_state = f.add_state()\n",
    "                f.set_final(word_final_state) \n",
    "                final_states.append(word_final_state)\n",
    "                word_final_list.append(i)\n",
    "                states_array[i, 0] = word_final_state \n",
    "                f.add_arc(start_state, fst.Arc(words_states_array[i, 0], \\\n",
    "                              word_table.find(word_list[i]), fst.Weight('log', \\\n",
    "                                                 -math.log(1)), word_final_state))\n",
    "            else:\n",
    "                state = f.add_state()\n",
    "                states_array[i, 0] = state\n",
    "                f.add_arc(start_state, fst.Arc(words_states_array[i, 0], 0, \\\n",
    "                                                 fst.Weight('log', \\\n",
    "                                                      -math.log(1)), state)) \n",
    "                f.add_arc(state, fst.Arc(words_states_array[i, 0], 0, \\\n",
    "                                        fst.Weight('log', -math.log(0.1)), state))\n",
    "    \n",
    "    for j in range(1, words_states_array.shape[1] - 1):\n",
    "        for i in range(words_states_array.shape[0]):\n",
    "            if words_states_array[i, j] != 0:\n",
    "                # If the word has state at this time step. \n",
    "                add_state = True \n",
    "                for index, array in enumerate(words_states_array[0:i, 0:j+1]):\n",
    "                    if np.allclose(words_states_array[i, 0:j+1], array):\n",
    "                        # If the previous words have the same states at all the previous time steps \n",
    "                        # and this time step. \n",
    "                        add_state = False\n",
    "                        states_array[i, 0:j+1] = states_array[index, 0:j+1]\n",
    "                        break\n",
    "\n",
    "                if add_state: \n",
    "                    if words_states_array[i, j+1] == 0:\n",
    "                        # If the word has phone at next time step. \n",
    "                        word_final_state = f.add_state() \n",
    "                        f.set_final(word_final_state)\n",
    "                        final_states.append(word_final_state)\n",
    "                        word_final_list.append(i)\n",
    "                        states_array[i, j] = word_final_state\n",
    "                        f.add_arc(states_array[i, j-1], fst.Arc(words_states_array[i, j], \\\n",
    "                                word_table.find(word_list[i]), fst.Weight('log', -math.log(1)), word_final_state))\n",
    "                    else:\n",
    "                        state = f.add_state()\n",
    "                        states_array[i, j] = state\n",
    "                        f.add_arc(states_array[i, j-1], fst.Arc(words_states_array[i, j], 0, \\\n",
    "                                                                fst.Weight('log', -math.log(0.9)), state)) \n",
    "                        f.add_arc(state, fst.Arc(words_states_array[i, j], 0, \\\n",
    "                                                fst.Weight('log', -math.log(0.1)), state))\n",
    "    # for state in final_states:\n",
    "    for i in range(len(final_states)):\n",
    "        f.add_arc(final_states[i], fst.Arc(0, 0, fst.Weight('log', \\\n",
    "                                     -math.log(1)), start_state))\n",
    "    \n",
    "    return f, words_states_array, states_array, word_list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_wfst, words_states_array, states_array, word_list = generate_tree_wfst(word_state_dict)\n",
    "tree_wfst.set_input_symbols(state_sil_table)\n",
    "tree_wfst.set_output_symbols(word_table)\n",
    "from subprocess import check_call\n",
    "from IPython.display import Image \n",
    "tree_wfst.draw('tmp.dot', portrait=True)\n",
    "check_call(['dot','-Tpng','-Gdpi=200','tmp.dot','-o','tmp.png'])\n",
    "Image(filename='tmp.png') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from collections import defaultdict\n",
    "def read_transcription(wav_file):\n",
    "    \"\"\"\n",
    "    Get the transcription corresponding to wav_file.\n",
    "    \"\"\"\n",
    "    \n",
    "    transcription_file = os.path.splitext(wav_file)[0] + '.txt'\n",
    "    \n",
    "    with open(transcription_file, 'r') as f:\n",
    "        transcription = f.readline().strip()\n",
    "    \n",
    "    return transcription\n",
    "word_prob = defaultdict(float)  # word_prob contains the unigram probability for each word. \n",
    "total_word = 0 \n",
    "for wav_file in glob.glob('/group/teaching/asr/labs/recordings/*.wav'):\n",
    "    transcription = read_transcription(wav_file)\n",
    "    for word in transcription.split():\n",
    "        word_prob[word] += 1\n",
    "        total_word += 1\n",
    "for word in word_prob.keys():\n",
    "    word_prob[word] = word_prob[word] / total_word "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram_lm_look_ahead_prob = {}\n",
    "for i in range(states_array.shape[0]):\n",
    "    for j in range(states_array.shape[1]):\n",
    "        if states_array[i, j] not in unigram_lm_look_ahead_prob.keys():\n",
    "            # unigram_lm_look_ahead_prob[int(states_array[i, j])] = 0\n",
    "            unigram_lm_look_ahead_prob[int(states_array[i, j])] = word_prob[word_list[i]]\n",
    "        else:\n",
    "            unigram_lm_look_ahead_prob[int(states_array[i, j])] = \\\n",
    "                                          max(unigram_lm_look_ahead_prob[int(states_array[i, j])],\n",
    "                                                                word_prob[word_list[i]]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_sequence_wfst = generate_word_sequence_wfst(3)\n",
    "word_sequence_wfst.set_input_symbols(state_table)\n",
    "word_sequence_wfst.set_output_symbols(word_table)\n",
    "from subprocess import check_call\n",
    "from IPython.display import Image \n",
    "word_sequence_wfst.draw('tmp.dot', portrait=True)\n",
    "check_call(['dot','-Tpng','-Gdpi=200','tmp.dot','-o','tmp.png'])\n",
    "Image(filename='tmp.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_unigram_word_wfst(n=3):\n",
    "    \n",
    "    '''\n",
    "    Generate a wfst contains unigram grammer to recognize word sequences. \n",
    "    '''\n",
    "    \n",
    "    f = fst.Fst('log')\n",
    "    \n",
    "    # create a single start state\n",
    "    start_state = f.add_state()\n",
    "    f.set_start(start_state)\n",
    "    \n",
    "    for word, phones in lex.items():\n",
    "        current_state = f.add_state()\n",
    "        # The transition probability to each word is unigram probability. \n",
    "        f.add_arc(start_state, fst.Arc(0, word_table.find(word),\\\n",
    "                                       fst.Weight('log', -math.log(word_prob[word])), current_state)) \n",
    "        \n",
    "        for phone in phones: \n",
    "            current_state = generate_phone_wfst(f, current_state, phone, n)\n",
    "        # note: new current_state is now set to the final state of the previous phone WFST\n",
    "        \n",
    "        f.set_final(current_state)\n",
    "        f.add_arc(current_state, fst.Arc(0, 0, fst.Weight('log', -math.log(1)), start_state))\n",
    "        \n",
    "    return f "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram_sequence_wfst = generate_unigram_word_wfst()\n",
    "unigram_sequence_wfst.set_input_symbols(state_table)\n",
    "unigram_sequence_wfst.set_output_symbols(word_table)\n",
    "from subprocess import check_call\n",
    "from IPython.display import Image \n",
    "unigram_sequence_wfst.draw('tmp.dot', portrait=True)\n",
    "check_call(['dot','-Tpng','-Gdpi=200','tmp.dot','-o','tmp.png'])\n",
    "Image(filename='tmp.png') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_word_sil_wfst(n=3):\n",
    "    \n",
    "    '''\n",
    "    Generate word_sil_wfst which contains five silence states at the end of each word. \n",
    "    During decoding, the decoder has to go through the slience states. \n",
    "    '''\n",
    "    \n",
    "    f = fst.Fst('log')\n",
    "    start_state = f.add_state()\n",
    "    f.set_start(start_state)\n",
    "    \n",
    "    for word, phones in lex.items():\n",
    "        current_state = f.add_state()\n",
    "        f.add_arc(start_state, fst.Arc(0, word_table.find(word), fst.Weight('log', -math.log(word_prob[word])), \\\n",
    "                                      current_state))\n",
    "        for phone in phones:\n",
    "            current_state = generate_phone_wfst(f, current_state, phone, n)\n",
    "            \n",
    "        phone_final_state = current_state \n",
    "        last_state = phone_final_state \n",
    "        \n",
    "        for i in range(1, 6):\n",
    "            current_state = f.add_state()\n",
    "            f.add_arc(last_state, fst.Arc(state_sil_table.find('sil_{}'.format(i)), 0, \\\n",
    "                                         fst.Weight('log', -math.log(0.9)), current_state))\n",
    "            f.add_arc(last_state, fst.Arc(state_sil_table.find('sil_{}'.format(i)), 0, \\\n",
    "                                            fst.Weight('log', -math.log(0.1)), last_state))\n",
    "            last_state = current_state\n",
    "            \n",
    "        word_final_state = last_state\n",
    "        f.set_final(word_final_state)\n",
    "        \n",
    "        f.add_arc(word_final_state, fst.Arc(0, 0, fst.Weight('log', -math.log(1)), start_state)) \n",
    "        \n",
    "    return f "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_sil_wfst = generate_word_sil_wfst()\n",
    "word_sil_wfst.set_input_symbols(state_sil_table) \n",
    "word_sil_wfst.set_output_symbols(word_table)\n",
    "from subprocess import check_call\n",
    "from IPython.display import Image \n",
    "word_sil_wfst.draw('tmp.dot', portrait=True)\n",
    "check_call(['dot','-Tpng','-Gdpi=200','tmp.dot','-o','tmp.png'])\n",
    "Image(filename='tmp.png') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sequence_sil_wfst(n=3):\n",
    "    \n",
    "    '''\n",
    "    Generate sequence_sil_wfst which chotains five silence states at the end of each word. \n",
    "    During decoding, the decoder can go through the silence states or not depending on the given probabilities. \n",
    "    '''\n",
    "    \n",
    "    f = fst.Fst('log')\n",
    "    start_state = f.add_state()\n",
    "    f.set_start(start_state)\n",
    "    \n",
    "    for word, phones in lex.items():\n",
    "        current_state = f.add_state()\n",
    "        f.add_arc(start_state, fst.Arc(0, word_table.find(word), fst.Weight('log', -math.log(word_prob[word])), \\\n",
    "                                      current_state))\n",
    "        for phone in phones:\n",
    "            current_state = generate_phone_wfst(f, current_state, phone, n)\n",
    "            \n",
    "        phone_final_state = current_state \n",
    "        current_state = f.add_state()\n",
    "        \n",
    "        f.add_arc(phone_final_state, fst.Arc(state_sil_table.find('sil_1'), 0, \\\n",
    "                                            fst.Weight('log', -math.log(0.9*0.8)), current_state))\n",
    "        f.add_arc(phone_final_state, fst.Arc(state_sil_table.find('sil_1'), 0, \\\n",
    "                                        fst.Weight('log', -math.log(0.1)), phone_final_state))\n",
    "        last_state = current_state \n",
    "        \n",
    "        for i in range(2, 6):\n",
    "            current_state = f.add_state()\n",
    "            f.add_arc(last_state, fst.Arc(state_sil_table.find('sil_{}'.format(i)), 0, \\\n",
    "                                         fst.Weight('log', -math.log(0.9)), current_state))\n",
    "            f.add_arc(last_state, fst.Arc(state_sil_table.find('sil_{}'.format(i)), 0, \\\n",
    "                                            fst.Weight('log', -math.log(0.1)), last_state))\n",
    "            last_state = current_state\n",
    "            \n",
    "            \n",
    "        word_final_state = last_state\n",
    "        f.set_final(word_final_state)\n",
    "        f.add_arc(phone_final_state, fst.Arc(state_table.find('{}_{}'.format(phone, n)), 0, \\\n",
    "                                      fst.Weight('log', -math.log(0.9*0.2)), word_final_state))\n",
    "        f.add_arc(word_final_state, fst.Arc(0, 0, fst.Weight('log', -math.log(1)), start_state)) \n",
    "        \n",
    "    return f  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_sil_wfst = generate_sequence_sil_wfst()\n",
    "sequence_sil_wfst.set_input_symbols(state_sil_table)\n",
    "sequence_sil_wfst.set_output_symbols(word_table)\n",
    "from subprocess import check_call\n",
    "from IPython.display import Image \n",
    "sequence_sil_wfst.draw('tmp.dot', portrait=True)\n",
    "check_call(['dot','-Tpng','-Gdpi=200','tmp.dot','-o','tmp.png'])\n",
    "Image(filename='tmp.png')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_unigram_wfst():\n",
    "    \n",
    "    '''\n",
    "    Generate unigram_wfst which contains the unigram grammar of the words. \n",
    "    '''\n",
    "    \n",
    "    f = fst.Fst('log')\n",
    "    # f = fst.Fst()\n",
    "    state = f.add_state()\n",
    "    f.set_start(state)\n",
    "    for word in lex.keys():\n",
    "        f.add_arc(state, fst.Arc(word_table.find(word), word_table.find(word),\\\n",
    "                                fst.Weight('log', -math.log(word_prob[word])), state))\n",
    "        \n",
    "    f.set_final(state)\n",
    "    return f "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram_wfst = generate_unigram_wfst()\n",
    "unigram_wfst.set_input_symbols(word_table)\n",
    "unigram_wfst.set_output_symbols(word_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_hmm_transducer(n=3):\n",
    "    \"\"\" generate a HMM to recognise any single phone sequence in the lexicon\n",
    "    \n",
    "    Args:\n",
    "        n (int): states per phone HMM\n",
    "\n",
    "    Returns:\n",
    "        the constructed WFST\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    f = fst.Fst('log')\n",
    "    \n",
    "    # create a single start state\n",
    "    start_state = f.add_state()\n",
    "    f.set_start(start_state)\n",
    "    \n",
    "    phone_set = set()\n",
    "    \n",
    "    for pronunciation in lex.values():\n",
    "        phone_set = phone_set.union(pronunciation)\n",
    "        \n",
    "    for phone in phone_set:\n",
    "        current_state = f.add_state()\n",
    "        f.add_arc(start_state, fst.Arc(0, 0, fst.Weight('log', -math.log(1)), current_state))\n",
    "    \n",
    "        end_state = generate_phone_wfst(f, current_state, phone, n, output_phone=True)\n",
    "        \n",
    "        f.add_arc(end_state, fst.Arc(0,0, fst.Weight('log', -math.log(1)), start_state))\n",
    "        f.set_final(end_state)\n",
    "            \n",
    "    return f "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmm_transducer = generate_hmm_transducer() \n",
    "hmm_transducer.set_input_symbols(state_table)\n",
    "hmm_transducer.set_output_symbols(phone_table)\n",
    "from subprocess import check_call\n",
    "from IPython.display import Image \n",
    "hmm_transducer.draw('tmp.dot', portrait=True)\n",
    "check_call(['dot','-Tpng','-Gdpi=200','tmp.dot','-o','tmp.png'])\n",
    "Image(filename='tmp.png') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tree_sequence_wfst = fst.determinize(fst.compose(hmm_transducer, \\\n",
    "                            # fst.determinize(fst.compose(tree_lexicon, unigram_wfst)).minimize())).minimize()\n",
    "# tree_sequence_wfst = fst.determinize(fst.compose(hmm_transducer, \\\n",
    "                                 # fst.determinize(fst.compose(tree_lexicon, unigram_wfst)).minimize())).minimize()\n",
    "tree_sequence_wfst = fst.compose(tree_lexicon, unigram_wfst)\n",
    "# tree_sequence_wfst = fst.determinize(tree_sequence_wfst).minimize()\n",
    "# tree_sequence_wfst = fst.determinize(fst.compose(tree_lexicon, unigram_wfst)).minimize()\n",
    "# tree_sequence_wfst = fst.determinize(fst.compose(hmm_transducer, tree_sequence_wfst)).minimize()\n",
    "tree_sequence_wfst = fst.compose(hmm_transducer, tree_sequence_wfst) \n",
    "# tree_sequence_wfst = fst.determinize(tree_sequence_wfst).minimize()\n",
    "tree_sequence_wfst.set_input_symbols(state_table) \n",
    "tree_sequence_wfst.set_output_symbols(word_table) \n",
    "from subprocess import check_call \n",
    "from IPython.display import Image \n",
    "tree_sequence_wfst.draw('tmp.dot', portrait=True) \n",
    "check_call(['dot','-Tpng','-Gdpi=200','tmp.dot','-o','tmp.png'])\n",
    "Image(filename='tmp.png') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index_dict = {}\n",
    "for word in lex.keys():\n",
    "    word_index_dict[word] = word_table.find(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index_dict['#'] = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_bigram():\n",
    "    bigrams = defaultdict(int)\n",
    "    unigrams = defaultdict(int)\n",
    "    bigram_prob = {}\n",
    "    for wav_file in glob.glob('/group/teaching/asr/labs/recordings/*.wav'):\n",
    "        transcription = read_transcription(wav_file)\n",
    "        transcription = '# ' + transcription + ' #'\n",
    "        # We add a start symbol to give the first word bigram probability. We add an end symbol \n",
    "        # to make sure the probabilities of all sentences sum to one. \n",
    "        transcription = transcription.split()\n",
    "        for i in range(len(transcription) - 1):\n",
    "            bigrams[tuple(transcription[i:i+2])] += 1\n",
    "            unigrams[transcription[i]] += 1 \n",
    "    \n",
    "    for bigram in bigrams.keys():\n",
    "        bigram_prob[bigram] = bigrams[bigram] / unigrams[bigram[0]]\n",
    "        \n",
    "    return bigram_prob "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_prob = compute_bigram()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_prob_array = np.ones([len(lex.keys()) + 1, len(lex.keys()) + 1])\n",
    "# bigram_prob_array contains the bigram probabilities. \n",
    "# bigram_prob_array[i, j] means p(word[j]|word[i]) \n",
    "for bigram in bigram_prob.keys():\n",
    "    bigram_prob_array[word_index_dict[bigram[0]]][word_index_dict[bigram[1]]] = bigram_prob[bigram] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_bigram_word_wfst(n=3):\n",
    "    \n",
    "    '''\n",
    "    Generate bigram_sequence_wfst which does not have silence states. \n",
    "    '''\n",
    "    \n",
    "    f = fst.Fst('log')\n",
    "    start_state = f.add_state()\n",
    "    f.set_start(start_state)\n",
    "    word_start_states = []\n",
    "    word_final_states = []\n",
    "    word_index_list = []\n",
    "    for word, phones in lex.items(): \n",
    "        word_index_list.append(word_index_dict[word])\n",
    "        word_start_state = f.add_state()\n",
    "        \n",
    "        word_start_states.append(word_start_state)\n",
    "        f.add_arc(start_state, fst.Arc(0, 0,\\\n",
    "                                       fst.Weight('log', -math.log(bigram_prob_array[0, word_index_dict[word]])),\\\n",
    "                                       word_start_state))\n",
    "        current_state = f.add_state()\n",
    "        f.add_arc(word_start_state, fst.Arc(0, word_table.find(word),\\\n",
    "                                            fst.Weight('log', -math.log(1)), current_state))\n",
    "        \n",
    "        for phone in phones:\n",
    "            current_state = generate_phone_wfst(f, current_state, phone, n)\n",
    "        word_final_state = current_state\n",
    "        word_final_states.append(word_final_state) \n",
    "        f.set_final(word_final_state)\n",
    "        \n",
    "    final_state = f.add_state()\n",
    "    f.set_final(final_state)\n",
    "     \n",
    "    for i in range(len(word_final_states)): \n",
    "        f.add_arc(word_final_states[i], fst.Arc(0, 0, \\\n",
    "                     fst.Weight('log', -math.log(bigram_prob_array[word_index_list[i], 0])), final_state))\n",
    "        for j in range(len(word_start_states)):\n",
    "            f.add_arc(word_final_states[i], fst.Arc(0, 0, \\\n",
    "                  fst.Weight('log', -math.log(bigram_prob_array[word_index_list[i]][word_index_list[j]])),\\\n",
    "                                                  word_start_states[j]))\n",
    "     \n",
    "    return f "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_bigram_sil_wfst(n=3):\n",
    "    \n",
    "    '''\n",
    "    Generate bigram_sil_wfst which contains five silence at the end of each word. \n",
    "    '''\n",
    "    \n",
    "    f = fst.Fst('log')\n",
    "    start_state = f.add_state()\n",
    "    f.set_start(start_state)\n",
    "    word_start_states = []\n",
    "    word_final_states = []\n",
    "    word_index_list = []\n",
    "    for word, phones in lex.items(): \n",
    "        word_index_list.append(word_index_dict[word])\n",
    "        word_start_state = f.add_state()\n",
    "        \n",
    "        word_start_states.append(word_start_state)\n",
    "        f.add_arc(start_state, fst.Arc(0, 0,\\\n",
    "                                       fst.Weight('log', -math.log(bigram_prob_array[0, word_index_dict[word]])),\\\n",
    "                                       word_start_state))\n",
    "        current_state = f.add_state()\n",
    "        f.add_arc(word_start_state, fst.Arc(0, word_table.find(word),\\\n",
    "                                            fst.Weight('log', -math.log(1)), current_state))\n",
    "        \n",
    "        for phone in phones:\n",
    "            current_state = generate_phone_wfst(f, current_state, phone, n)\n",
    "        \n",
    "        phone_final_state = current_state \n",
    "        last_state = phone_final_state \n",
    "        \n",
    "        for i in range(1, 6):\n",
    "            current_state = f.add_state()\n",
    "            f.add_arc(last_state, fst.Arc(state_sil_table.find('sil_{}'.format(i)), 0, \\\n",
    "                                         fst.Weight('log', -math.log(0.9)), current_state))\n",
    "            f.add_arc(last_state, fst.Arc(state_sil_table.find('sil_{}'.format(i)), 0, \\\n",
    "                                            fst.Weight('log', -math.log(0.1)), last_state))\n",
    "            last_state = current_state\n",
    "            \n",
    "            \n",
    "        word_final_state = last_state\n",
    "        \n",
    "        \n",
    "        word_final_states.append(word_final_state) \n",
    "        f.set_final(word_final_state)\n",
    "        \n",
    "    final_state = f.add_state()\n",
    "    f.set_final(final_state)\n",
    "     \n",
    "    for i in range(len(word_final_states)): \n",
    "        f.add_arc(word_final_states[i], fst.Arc(0, 0, \\\n",
    "                     fst.Weight('log', -math.log(bigram_prob_array[word_index_list[i], 0])), final_state))\n",
    "        for j in range(len(word_start_states)):\n",
    "            f.add_arc(word_final_states[i], fst.Arc(0, 0, \\\n",
    "                  fst.Weight('log', -math.log(bigram_prob_array[word_index_list[i]][word_index_list[j]])),\\\n",
    "                                                  word_start_states[j]))\n",
    "     \n",
    "    return f  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_sequence_wfst = generate_bigram_word_wfst()\n",
    "bigram_sequence_wfst.set_input_symbols(state_table)\n",
    "bigram_sequence_wfst.set_output_symbols(word_table)\n",
    "from subprocess import check_call\n",
    "from IPython.display import Image \n",
    "bigram_sequence_wfst.draw('tmp.dot', portrait=True)\n",
    "check_call(['dot','-Tpng','-Gdpi=200','tmp.dot','-o','tmp.png'])\n",
    "Image(filename='tmp.png') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_sil_wfst = generate_bigram_sil_wfst()\n",
    "bigram_sil_wfst.set_input_symbols(state_sil_table)\n",
    "bigram_sil_wfst.set_output_symbols(word_table)\n",
    "from subprocess import check_call\n",
    "from IPython.display import Image \n",
    "bigram_sil_wfst.draw('tmp.dot', portrait=True) \n",
    "check_call(['dot','-Tpng','-Gdpi=200','tmp.dot','-o','tmp.png'])\n",
    "Image(filename='tmp.png') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram_word_wfst = fst.compose(word_sequence_wfst, unigram_wfst) \n",
    "from subprocess import check_call\n",
    "from IPython.display import Image \n",
    "unigram_word_wfst.draw('tmp.dot', portrait=True)\n",
    "check_call(['dot','-Tpng','-Gdpi=200','tmp.dot','-o','tmp.png'])\n",
    "Image(filename='tmp.png') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_states_arcs(f):\n",
    "    \n",
    "    '''\n",
    "    Compute num states and num arcs in the transducer. \n",
    "    '''\n",
    "    \n",
    "    total_states = 0\n",
    "    total_arcs = 0\n",
    "    for state in f.states():\n",
    "        total_states += 1 \n",
    "        for arc in f.arcs(state):\n",
    "            total_arcs += 1 \n",
    "    return total_states, total_arcs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import wer\n",
    "import observation_model\n",
    "import openfst_python as fst\n",
    "import time\n",
    "\n",
    "# ... (add your code to create WFSTs and Viterbi Decoder)\n",
    "\n",
    "def read_transcription(wav_file):\n",
    "    \"\"\"\n",
    "    Get the transcription corresponding to wav_file.\n",
    "    \"\"\"\n",
    "    \n",
    "    transcription_file = os.path.splitext(wav_file)[0] + '.txt'\n",
    "    \n",
    "    with open(transcription_file, 'r') as f:\n",
    "        transcription = f.readline().strip()\n",
    "    \n",
    "    return transcription\n",
    "\n",
    "\n",
    "# f = create_wfst()\n",
    "# f = create_wfst\n",
    "f = word_sequence_wfst \n",
    "f.set_input_symbols(state_table) \n",
    "f.set_output_symbols(word_table)\n",
    "# fdet = fst.determinize(f)\n",
    "\n",
    "total_decode_time = 0 \n",
    "total_backtrace_time = 0 \n",
    "total_errors = 0 \n",
    "total_words = 0 \n",
    "total_computations = 0 \n",
    "\n",
    "\n",
    "for wav_file in glob.glob('/group/teaching/asr/labs/recordings/*.wav'):    # replace path if using your own\n",
    "                                                                           # audio files\n",
    "    \n",
    "    decoder = MyViterbiDecoder(f, wav_file)\n",
    "    # decoder = MyViterbiDecoder(fdet, wav_file)\n",
    "    \n",
    "    decode_start_time = time.time()\n",
    "    computations = decoder.decode()\n",
    "    decode_end_time = time.time()\n",
    "    decode_time = decode_end_time - decode_start_time\n",
    "    total_decode_time += decode_time \n",
    "    print(decode_time) \n",
    "    total_computations += computations\n",
    "    print(computations) \n",
    "    # (state_path, words) = decoder.backtrace()  # you'll need to modify the backtrace() from Lab 4\n",
    "                                               # to return the words along the best path\n",
    "    backtrace_start_time = time.time()\n",
    "    # (state_path, phones) = decoder.backtrace()\n",
    "    (statee_path, words) = decoder.backtrace()\n",
    "    backtrace_end_time = time.time()\n",
    "    backtrace_time = backtrace_end_time - backtrace_start_time \n",
    "    total_backtrace_time += backtrace_time \n",
    "    print(backtrace_time)\n",
    "    # print(phones) \n",
    "    \n",
    "    \n",
    "    \n",
    "    print(words)\n",
    "    transcription = read_transcription(wav_file)\n",
    "    # print(transcription)\n",
    "    error_counts = wer.compute_alignment_errors(transcription, words)\n",
    "    word_count = len(transcription.split()) \n",
    "    total_errors += sum(error_counts)\n",
    "    total_words += word_count \n",
    "        \n",
    "    print(error_counts, word_count)     #you'll need to accumulate these to produce an overall Word Error Rate\n",
    "\n",
    "total_wer = total_errors / total_words \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('word_sequence_wfst')\n",
    "print('num states: {}, num arcs: {}'.format(*compute_states_arcs(word_sequence_wfst)))\n",
    "print('total decode time: {}'.format(total_decode_time))\n",
    "print('total backtrace time: {}'.format(total_backtrace_time))\n",
    "print('total forward computations: {}'.format(total_computations))\n",
    "print('total word error rate: {}'.format(total_wer)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "word_sequence_wfst\n",
    "num states: 116, num arcs: 230\n",
    "total decode time: 974.6350224018097\n",
    "total backtrace time: 0.16611146926879883\n",
    "total forward computations: 32513904\n",
    "total word error rate: 2.064502875924404 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = word_sequence_wfst \n",
    "f.set_input_symbols(state_table) \n",
    "f.set_output_symbols(word_table)\n",
    "# fdet = fst.determinize(f)\n",
    "\n",
    "total_decode_time = 0 \n",
    "total_backtrace_time = 0 \n",
    "total_errors = 0 \n",
    "total_words = 0 \n",
    "total_computations = 0 \n",
    "\n",
    "\n",
    "for wav_file in glob.glob('/group/teaching/asr/labs/recordings/*.wav'):    # replace path if using your own\n",
    "                                                                           # audio files\n",
    "    \n",
    "    decoder = MyViterbiDecoder(f, wav_file)\n",
    "    # decoder = MyViterbiDecoder(fdet, wav_file)\n",
    "    \n",
    "    decode_start_time = time.time()\n",
    "    computations = decoder.decode()\n",
    "    decode_end_time = time.time()\n",
    "    decode_time = decode_end_time - decode_start_time\n",
    "    total_decode_time += decode_time \n",
    "    print(decode_time) \n",
    "    total_computations += computations\n",
    "    print(computations) \n",
    "    # (state_path, words) = decoder.backtrace()  # you'll need to modify the backtrace() from Lab 4\n",
    "                                               # to return the words along the best path\n",
    "    backtrace_start_time = time.time()\n",
    "    # (state_path, phones) = decoder.backtrace()\n",
    "    (statee_path, words) = decoder.backtrace()\n",
    "    backtrace_end_time = time.time()\n",
    "    backtrace_time = backtrace_end_time - backtrace_start_time \n",
    "    total_backtrace_time += backtrace_time \n",
    "    print(backtrace_time) \n",
    "    print(words)\n",
    "    transcription = read_transcription(wav_file)\n",
    "    print(transcription)\n",
    "    error_counts = wer.compute_alignment_errors(transcription, words)\n",
    "    word_count = len(transcription.split()) \n",
    "    total_errors += sum(error_counts)\n",
    "    total_words += word_count \n",
    "        \n",
    "    print(error_counts, word_count)     #you'll need to accumulate these to produce an overall Word Error Rate\n",
    "\n",
    "total_wer = total_errors / total_words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('word_sequence_wfst')\n",
    "print('num states: {}, num arcs: {}'.format(*compute_states_arcs(word_sequence_wfst)))\n",
    "print('total decode time: {}'.format(total_decode_time))\n",
    "print('total backtrace time: {}'.format(total_backtrace_time))\n",
    "print('total forward computations: {}'.format(total_computations))\n",
    "print('total word error rate: {}'.format(total_wer)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_wer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = unigram_word_wfst \n",
    "f.set_input_symbols(state_table) \n",
    "f.set_output_symbols(word_table)\n",
    "# fdet = fst.determinize(f)\n",
    "\n",
    "total_decode_time = 0 \n",
    "total_backtrace_time = 0 \n",
    "total_errors = 0 \n",
    "total_words = 0 \n",
    "total_computations = 0 \n",
    "\n",
    "\n",
    "for wav_file in glob.glob('/group/teaching/asr/labs/recordings/*.wav'):    # replace path if using your own\n",
    "                                                                           # audio files\n",
    "    \n",
    "    decoder = MyViterbiDecoder(f, wav_file)\n",
    "    # decoder = MyViterbiDecoder(fdet, wav_file)\n",
    "    \n",
    "    decode_start_time = time.time()\n",
    "    computations = decoder.decode()\n",
    "    decode_end_time = time.time()\n",
    "    decode_time = decode_end_time - decode_start_time\n",
    "    total_decode_time += decode_time \n",
    "    print(decode_time) \n",
    "    total_computations += computations\n",
    "    print(computations) \n",
    "    # (state_path, words) = decoder.backtrace()  # you'll need to modify the backtrace() from Lab 4\n",
    "                                               # to return the words along the best path\n",
    "    backtrace_start_time = time.time()\n",
    "    # (state_path, phones) = decoder.backtrace()\n",
    "    (statee_path, words) = decoder.backtrace()\n",
    "    backtrace_end_time = time.time()\n",
    "    backtrace_time = backtrace_end_time - backtrace_start_time \n",
    "    total_backtrace_time += backtrace_time \n",
    "    print(backtrace_time)\n",
    "    \n",
    "    print(words)\n",
    "    transcription = read_transcription(wav_file)\n",
    "    print(transcription)\n",
    "    error_counts = wer.compute_alignment_errors(transcription, words)\n",
    "    word_count = len(transcription.split()) \n",
    "    total_errors += sum(error_counts)\n",
    "    total_words += word_count \n",
    "        \n",
    "    print(error_counts, word_count)     #you'll need to accumulate these to produce an overall Word Error Rate\n",
    "\n",
    "total_wer = total_errors / total_words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('unigram_word_wfst')\n",
    "print('num states: {}, num arcs: {}'.format(*compute_states_arcs(unigram_word_wfst)))\n",
    "print('total backtrace time: {}'.format(total_backtrace_time))\n",
    "print('total decode time: {}'.format(total_decode_time))\n",
    "print('total forward computations: {}'.format(total_computations))\n",
    "print('total word error rate: {}'.format(total_wer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "unigram_word_wfst\n",
    "num states: 116, num arcs: 230\n",
    "total backtrace time: 0.14623546600341797\n",
    "total decode time: 969.2153050899506\n",
    "total forward computations: 32513904\n",
    "total word error rate: 1.3919474116680361"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = unigram_sequence_wfst \n",
    "f.set_input_symbols(state_table) \n",
    "f.set_output_symbols(word_table)\n",
    "# fdet = fst.determinize(f)\n",
    "\n",
    "total_decode_time = 0 \n",
    "total_backtrace_time = 0 \n",
    "total_errors = 0 \n",
    "total_words = 0 \n",
    "total_computations = 0 \n",
    "\n",
    "\n",
    "for wav_file in glob.glob('/group/teaching/asr/labs/recordings/*.wav'):    # replace path if using your own\n",
    "                                                                           # audio files\n",
    "    \n",
    "    decoder = MyViterbiDecoder(f, wav_file)\n",
    "    # decoder = MyViterbiDecoder(fdet, wav_file)\n",
    "    \n",
    "    decode_start_time = time.time()\n",
    "    computations = decoder.decode()\n",
    "    decode_end_time = time.time()\n",
    "    decode_time = decode_end_time - decode_start_time\n",
    "    total_decode_time += decode_time \n",
    "    print(decode_time) \n",
    "    total_computations += computations\n",
    "    print(computations) \n",
    "    # (state_path, words) = decoder.backtrace()  # you'll need to modify the backtrace() from Lab 4\n",
    "                                               # to return the words along the best path\n",
    "    backtrace_start_time = time.time()\n",
    "    # (state_path, phones) = decoder.backtrace()\n",
    "    (statee_path, words) = decoder.backtrace()\n",
    "    backtrace_end_time = time.time()\n",
    "    backtrace_time = backtrace_end_time - backtrace_start_time \n",
    "    total_backtrace_time += backtrace_time \n",
    "    print(backtrace_time) \n",
    "    print(words)\n",
    "    transcription = read_transcription(wav_file)\n",
    "    print(transcription)\n",
    "    error_counts = wer.compute_alignment_errors(transcription, words)\n",
    "    word_count = len(transcription.split()) \n",
    "    total_errors += sum(error_counts)\n",
    "    total_words += word_count \n",
    "        \n",
    "    print(error_counts, word_count)     #you'll need to accumulate these to produce an overall Word Error Rate\n",
    "\n",
    "total_wer = total_errors / total_words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('unigram sequence with transition probability 0.5')\n",
    "print('num states: {}, num arcs: {}'.format(*compute_states_arcs(unigram_sequence_wfst)))\n",
    "print('total backtrace time: {}'.format(total_backtrace_time))\n",
    "print('total decode time: {}'.format(total_decode_time))\n",
    "print('total forward computations: {}'.format(total_computations))\n",
    "print('total word error rate: {}'.format(total_wer)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = unigram_sequence_wfst \n",
    "f.set_input_symbols(state_table) \n",
    "f.set_output_symbols(word_table)\n",
    "# fdet = fst.determinize(f)\n",
    "\n",
    "total_decode_time = 0 \n",
    "total_backtrace_time = 0 \n",
    "total_errors = 0 \n",
    "total_words = 0 \n",
    "total_computations = 0 \n",
    "\n",
    "\n",
    "for wav_file in glob.glob('/group/teaching/asr/labs/recordings/*.wav'):    # replace path if using your own\n",
    "                                                                           # audio files\n",
    "    \n",
    "    decoder = MyViterbiDecoder(f, wav_file)\n",
    "    # decoder = MyViterbiDecoder(fdet, wav_file)\n",
    "    \n",
    "    decode_start_time = time.time()\n",
    "    computations = decoder.decode()\n",
    "    decode_end_time = time.time()\n",
    "    decode_time = decode_end_time - decode_start_time\n",
    "    total_decode_time += decode_time \n",
    "    print(decode_time) \n",
    "    total_computations += computations\n",
    "    print(computations) \n",
    "    # (state_path, words) = decoder.backtrace()  # you'll need to modify the backtrace() from Lab 4\n",
    "                                               # to return the words along the best path\n",
    "    backtrace_start_time = time.time()\n",
    "    # (state_path, phones) = decoder.backtrace()\n",
    "    (statee_path, words) = decoder.backtrace()\n",
    "    backtrace_end_time = time.time()\n",
    "    backtrace_time = backtrace_end_time - backtrace_start_time \n",
    "    total_backtrace_time += backtrace_time \n",
    "    print(backtrace_time) \n",
    "    print(words)\n",
    "    transcription = read_transcription(wav_file)\n",
    "    print(transcription)\n",
    "    error_counts = wer.compute_alignment_errors(transcription, words)\n",
    "    word_count = len(transcription.split()) \n",
    "    total_errors += sum(error_counts)\n",
    "    total_words += word_count \n",
    "        \n",
    "    print(error_counts, word_count)     #you'll need to accumulate these to produce an overall Word Error Rate\n",
    "\n",
    "total_wer = total_errors / total_words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('unigram sequence with transition probability 0.8')\n",
    "print('num states: {}, num arcs: {}'.format(*compute_states_arcs(unigram_sequence_wfst)))\n",
    "print('total backtrace time: {}'.format(total_backtrace_time))\n",
    "print('total decode time: {}'.format(total_decode_time))\n",
    "print('total forward computations: {}'.format(total_computations))\n",
    "print('total word error rate: {}'.format(total_wer)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('tree wfst')\n",
    "print('num states: {}, num arcs: {}'.format(*compute_states_arcs(tree_wfst)))\n",
    "print('total backtrace time: {}'.format(total_backtrace_time))\n",
    "print('total decode time: {}'.format(total_decode_time))\n",
    "print('total forward computations: {}'.format(total_computations))\n",
    "print('total word error rate: {}'.format(total_wer)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('tree wfst with beam width 0.1.')\n",
    "print('num states: {}, num arcs: {}'.format(*compute_states_arcs(tree_wfst)))\n",
    "print('total backtrace time: {}'.format(total_backtrace_time))\n",
    "print('total decode time: {}'.format(total_decode_time))\n",
    "print('total forward computations: {}'.format(total_computations))\n",
    "print('total word error rate: {}'.format(total_wer)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "unigram word wfst with beam width 10.\n",
    "num states: 116, num arcs: 230\n",
    "total backtrace time: 0.13636112213134766\n",
    "total decode time: 165.58465719223022\n",
    "total forward computations: 4413984\n",
    "total word error rate: 2.058340180772391"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = bigram_sequence_wfst \n",
    "f.set_input_symbols(state_table) \n",
    "f.set_output_symbols(word_table) \n",
    "\n",
    "total_decode_time = 0 \n",
    "total_backtrace_time = 0 \n",
    "total_errors = 0 \n",
    "total_words = 0 \n",
    "total_computations = 0 \n",
    "\n",
    "\n",
    "for wav_file in glob.glob('/group/teaching/asr/labs/recordings/*.wav'):    # replace path if using your own\n",
    "                                                                           # audio files\n",
    "    \n",
    "    decoder = MyViterbiDecoder(f, wav_file) \n",
    "    # decoder = MyViterbiDecoder(fdet, wav_file)\n",
    "    \n",
    "    decode_start_time = time.time()\n",
    "    computations = decoder.decode()\n",
    "    decode_end_time = time.time()\n",
    "    decode_time = decode_end_time - decode_start_time\n",
    "    total_decode_time += decode_time \n",
    "    print(decode_time) \n",
    "    total_computations += computations\n",
    "    print(computations) \n",
    "    # (state_path, words) = decoder.backtrace()  # you'll need to modify the backtrace() from Lab 4\n",
    "                                               # to return the words along the best path\n",
    "    backtrace_start_time = time.time()\n",
    "    # (state_path, phones) = decoder.backtrace()\n",
    "    (statee_path, words) = decoder.backtrace()\n",
    "    backtrace_end_time = time.time()\n",
    "    backtrace_time = backtrace_end_time - backtrace_start_time \n",
    "    total_backtrace_time += backtrace_time \n",
    "    print(backtrace_time) \n",
    "    print(words)\n",
    "    transcription = read_transcription(wav_file)\n",
    "    print(transcription)\n",
    "    error_counts = wer.compute_alignment_errors(transcription, words)\n",
    "    word_count = len(transcription.split()) \n",
    "    total_errors += sum(error_counts)\n",
    "    total_words += word_count \n",
    "        \n",
    "    print(error_counts, word_count)     #you'll need to accumulate these to produce an overall Word Error Rate\n",
    "\n",
    "total_wer = total_errors / total_words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('bigram_sequence_wfst')\n",
    "print('num states: {}, num arcs: {}'.format(*compute_states_arcs(bigram_sequence_wfst)))\n",
    "print('total backtrace time: {}'.format(total_backtrace_time))\n",
    "print('total decode time: {}'.format(total_decode_time))\n",
    "print('total forward computations: {}'.format(total_computations))\n",
    "print('total word error rate: {}'.format(total_wer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bigram_sequence_wfst\n",
    "num states: 127, num arcs: 340\n",
    "total backtrace time: 0.17756962776184082\n",
    "total decode time: 1132.2548327445984\n",
    "total forward computations: 32513904\n",
    "total word error rate: 1.97493837304848 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "unigram sequence wfst with beam width 10\n",
    "num states: 116, num arcs: 230\n",
    "total backtrace time: 0.1216437816619873\n",
    "total decode time: 168.6038625240326\n",
    "total forward computations: 4413984\n",
    "total word error rate: 1.9231717337715695 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = word_sil_wfst \n",
    "f.set_input_symbols(state_sil_table) \n",
    "f.set_output_symbols(word_table) \n",
    "\n",
    "total_decode_time = 0 \n",
    "total_backtrace_time = 0 \n",
    "total_errors = 0 \n",
    "total_words = 0 \n",
    "total_computations = 0 \n",
    "\n",
    "\n",
    "for wav_file in glob.glob('/group/teaching/asr/labs/recordings/*.wav'):    # replace path if using your own\n",
    "                                                                           # audio files\n",
    "    \n",
    "    decoder = MyViterbiDecoder(f, wav_file) \n",
    "    # decoder = MyViterbiDecoder(fdet, wav_file)\n",
    "    \n",
    "    decode_start_time = time.time()\n",
    "    computations = decoder.decode()\n",
    "    decode_end_time = time.time()\n",
    "    decode_time = decode_end_time - decode_start_time\n",
    "    total_decode_time += decode_time \n",
    "    print(decode_time) \n",
    "    total_computations += computations\n",
    "    print(computations) \n",
    "    # (state_path, words) = decoder.backtrace()  # you'll need to modify the backtrace() from Lab 4\n",
    "                                               # to return the words along the best path\n",
    "    backtrace_start_time = time.time()\n",
    "    # (state_path, phones) = decoder.backtrace()\n",
    "    (statee_path, words) = decoder.backtrace()\n",
    "    backtrace_end_time = time.time()\n",
    "    backtrace_time = backtrace_end_time - backtrace_start_time \n",
    "    total_backtrace_time += backtrace_time \n",
    "    print(backtrace_time)  \n",
    "    print(words)\n",
    "    transcription = read_transcription(wav_file)\n",
    "    print(transcription)\n",
    "    error_counts = wer.compute_alignment_errors(transcription, words)\n",
    "    word_count = len(transcription.split()) \n",
    "    total_errors += sum(error_counts)\n",
    "    total_words += word_count \n",
    "        \n",
    "    print(error_counts, word_count)     #you'll need to accumulate these to produce an overall Word Error Rate\n",
    "\n",
    "total_wer = total_errors / total_words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('word sil wfst')\n",
    "print('num states: {}, num arcs: {}'.format(*compute_states_arcs(word_sil_wfst)))\n",
    "print('total backtrace time: {}'.format(total_backtrace_time))\n",
    "print('total decode time: {}'.format(total_decode_time))\n",
    "print('total forward computations: {}'.format(total_computations))\n",
    "print('total word error rate: {}'.format(total_wer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "word sil wfst\n",
    "num states: 166, num arcs: 330\n",
    "total backtrace time: 0.1423349380493164\n",
    "total decode time: 1387.7171621322632\n",
    "total forward computations: 47778204\n",
    "total word error rate: 0.5357436318816763 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = word_sil_wfst \n",
    "f.set_input_symbols(state_sil_table) \n",
    "f.set_output_symbols(word_table) \n",
    "\n",
    "total_decode_time = 0 \n",
    "total_backtrace_time = 0 \n",
    "total_errors = 0 \n",
    "total_words = 0 \n",
    "total_computations = 0 \n",
    "\n",
    "\n",
    "for wav_file in glob.glob('/group/teaching/asr/labs/recordings/*.wav'):    # replace path if using your own\n",
    "                                                                           # audio files\n",
    "    \n",
    "    decoder = MyViterbiDecoder(f, wav_file, beam_size=10) \n",
    "    # decoder = MyViterbiDecoder(fdet, wav_file)\n",
    "    \n",
    "    decode_start_time = time.time()\n",
    "    computations = decoder.decode()\n",
    "    decode_end_time = time.time()\n",
    "    decode_time = decode_end_time - decode_start_time\n",
    "    total_decode_time += decode_time \n",
    "    print(decode_time) \n",
    "    total_computations += computations\n",
    "    print(computations) \n",
    "    # (state_path, words) = decoder.backtrace()  # you'll need to modify the backtrace() from Lab 4\n",
    "                                               # to return the words along the best path\n",
    "    backtrace_start_time = time.time()\n",
    "    # (state_path, phones) = decoder.backtrace()\n",
    "    (statee_path, words) = decoder.backtrace()\n",
    "    backtrace_end_time = time.time()\n",
    "    backtrace_time = backtrace_end_time - backtrace_start_time \n",
    "    total_backtrace_time += backtrace_time \n",
    "    print(backtrace_time) \n",
    "    print(words)\n",
    "    transcription = read_transcription(wav_file)\n",
    "    print(transcription)\n",
    "    error_counts = wer.compute_alignment_errors(transcription, words)\n",
    "    word_count = len(transcription.split()) \n",
    "    total_errors += sum(error_counts)\n",
    "    total_words += word_count \n",
    "        \n",
    "    print(error_counts, word_count)     #you'll need to accumulate these to produce an overall Word Error Rate\n",
    "\n",
    "total_wer = total_errors / total_words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('word sil wfst with beam size 10.')\n",
    "print('num states: {}, num arcs: {}'.format(*compute_states_arcs(word_sil_wfst)))\n",
    "print('total backtrace time: {}'.format(total_backtrace_time))\n",
    "print('total decode time: {}'.format(total_decode_time))\n",
    "print('total forward computations: {}'.format(total_computations))\n",
    "print('total word error rate: {}'.format(total_wer)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "word sil wfst with beam size 10.\n",
    "num states: 166, num arcs: 330\n",
    "total backtrace time: 0.13271570205688477\n",
    "total decode time: 193.65572690963745\n",
    "total forward computations: 4826666\n",
    "total word error rate: 0.8870172555464256 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.13, 0.15, 0.15, 0.15, \n",
    "print(np.array([193.66, 346.09, 507.74, 704.56]) / 1387.72)\n",
    "print(np.array([4826666, 9777744, 15555670, 21399724]) / 47778204) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = word_sil_wfst \n",
    "f.set_input_symbols(state_sil_table) \n",
    "f.set_output_symbols(word_table) \n",
    "\n",
    "total_decode_time = 0 \n",
    "total_backtrace_time = 0 \n",
    "total_errors = 0 \n",
    "total_words = 0 \n",
    "total_computations = 0 \n",
    "\n",
    "\n",
    "for wav_file in glob.glob('/group/teaching/asr/labs/recordings/*.wav'):    # replace path if using your own\n",
    "                                                                           # audio files\n",
    "    \n",
    "    decoder = MyViterbiDecoder(f, wav_file, beam_size=30) \n",
    "    # decoder = MyViterbiDecoder(fdet, wav_file)\n",
    "    \n",
    "    decode_start_time = time.time()\n",
    "    computations = decoder.decode()\n",
    "    decode_end_time = time.time()\n",
    "    decode_time = decode_end_time - decode_start_time\n",
    "    total_decode_time += decode_time \n",
    "    print(decode_time) \n",
    "    total_computations += computations\n",
    "    print(computations) \n",
    "    # (state_path, words) = decoder.backtrace()  # you'll need to modify the backtrace() from Lab 4\n",
    "                                               # to return the words along the best path\n",
    "    backtrace_start_time = time.time()\n",
    "    # (state_path, phones) = decoder.backtrace()\n",
    "    (statee_path, words) = decoder.backtrace()\n",
    "    backtrace_end_time = time.time()\n",
    "    backtrace_time = backtrace_end_time - backtrace_start_time \n",
    "    total_backtrace_time += backtrace_time \n",
    "    print(backtrace_time) \n",
    "    print(words)\n",
    "    transcription = read_transcription(wav_file)\n",
    "    print(transcription)\n",
    "    error_counts = wer.compute_alignment_errors(transcription, words)\n",
    "    word_count = len(transcription.split()) \n",
    "    total_errors += sum(error_counts)\n",
    "    total_words += word_count \n",
    "        \n",
    "    print(error_counts, word_count)     #you'll need to accumulate these to produce an overall Word Error Rate\n",
    "\n",
    "total_wer = total_errors / total_words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('word sil wfst with beam size 30.')\n",
    "print('num states: {}, num arcs: {}'.format(*compute_states_arcs(word_sil_wfst)))\n",
    "print('total backtrace time: {}'.format(total_backtrace_time))\n",
    "print('total decode time: {}'.format(total_decode_time))\n",
    "print('total forward computations: {}'.format(total_computations))\n",
    "print('total word error rate: {}'.format(total_wer)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "word sil wfst with beam size 30.\n",
    "num states: 166, num arcs: 330\n",
    "total backtrace time: 0.1462109088897705\n",
    "total decode time: 346.09289479255676\n",
    "total forward computations: 9777744\n",
    "total word error rate: 0.6322925225965489 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = word_sil_wfst \n",
    "f.set_input_symbols(state_sil_table) \n",
    "f.set_output_symbols(word_table) \n",
    "\n",
    "total_decode_time = 0 \n",
    "total_backtrace_time = 0 \n",
    "total_errors = 0 \n",
    "total_words = 0 \n",
    "total_computations = 0 \n",
    "\n",
    "\n",
    "for wav_file in glob.glob('/group/teaching/asr/labs/recordings/*.wav'):    # replace path if using your own\n",
    "                                                                           # audio files\n",
    "    \n",
    "    decoder = MyViterbiDecoder(f, wav_file, beam_size=50) \n",
    "    # decoder = MyViterbiDecoder(fdet, wav_file)\n",
    "    \n",
    "    decode_start_time = time.time()\n",
    "    computations = decoder.decode()\n",
    "    decode_end_time = time.time()\n",
    "    decode_time = decode_end_time - decode_start_time\n",
    "    total_decode_time += decode_time \n",
    "    print(decode_time) \n",
    "    total_computations += computations\n",
    "    print(computations) \n",
    "    # (state_path, words) = decoder.backtrace()  # you'll need to modify the backtrace() from Lab 4\n",
    "                                               # to return the words along the best path\n",
    "    backtrace_start_time = time.time()\n",
    "    # (state_path, phones) = decoder.backtrace()\n",
    "    (statee_path, words) = decoder.backtrace()\n",
    "    backtrace_end_time = time.time()\n",
    "    backtrace_time = backtrace_end_time - backtrace_start_time \n",
    "    total_backtrace_time += backtrace_time \n",
    "    print(backtrace_time) \n",
    "    print(words)\n",
    "    transcription = read_transcription(wav_file)\n",
    "    print(transcription)\n",
    "    error_counts = wer.compute_alignment_errors(transcription, words)\n",
    "    word_count = len(transcription.split()) \n",
    "    total_errors += sum(error_counts)\n",
    "    total_words += word_count \n",
    "        \n",
    "    print(error_counts, word_count)     #you'll need to accumulate these to produce an overall Word Error Rate\n",
    "\n",
    "total_wer = total_errors / total_words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('word sil wfst with beam size 50.')\n",
    "print('num states: {}, num arcs: {}'.format(*compute_states_arcs(word_sil_wfst)))\n",
    "print('total backtrace time: {}'.format(total_backtrace_time))\n",
    "print('total decode time: {}'.format(total_decode_time))\n",
    "print('total forward computations: {}'.format(total_computations))\n",
    "print('total word error rate: {}'.format(total_wer)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "word sil wfst with beam size 50.\n",
    "num states: 166, num arcs: 330\n",
    "total backtrace time: 0.1522197723388672\n",
    "total decode time: 507.74493885040283\n",
    "total forward computations: 15555670\n",
    "total word error rate: 0.5579293344289236 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = word_sil_wfst \n",
    "f.set_input_symbols(state_sil_table) \n",
    "f.set_output_symbols(word_table) \n",
    "\n",
    "total_decode_time = 0 \n",
    "total_backtrace_time = 0 \n",
    "total_errors = 0 \n",
    "total_words = 0 \n",
    "total_computations = 0 \n",
    "\n",
    "\n",
    "for wav_file in glob.glob('/group/teaching/asr/labs/recordings/*.wav'):    # replace path if using your own\n",
    "                                                                           # audio files\n",
    "    \n",
    "    decoder = MyViterbiDecoder(f, wav_file, beam_size=70) \n",
    "    # decoder = MyViterbiDecoder(fdet, wav_file)\n",
    "    \n",
    "    decode_start_time = time.time()\n",
    "    computations = decoder.decode()\n",
    "    decode_end_time = time.time()\n",
    "    decode_time = decode_end_time - decode_start_time\n",
    "    total_decode_time += decode_time \n",
    "    print(decode_time) \n",
    "    total_computations += computations\n",
    "    print(computations) \n",
    "    # (state_path, words) = decoder.backtrace()  # you'll need to modify the backtrace() from Lab 4\n",
    "                                               # to return the words along the best path\n",
    "    backtrace_start_time = time.time()\n",
    "    # (state_path, phones) = decoder.backtrace()\n",
    "    (statee_path, words) = decoder.backtrace()\n",
    "    backtrace_end_time = time.time()\n",
    "    backtrace_time = backtrace_end_time - backtrace_start_time \n",
    "    total_backtrace_time += backtrace_time \n",
    "    print(backtrace_time) \n",
    "    print(words)\n",
    "    transcription = read_transcription(wav_file)\n",
    "    print(transcription)\n",
    "    error_counts = wer.compute_alignment_errors(transcription, words)\n",
    "    word_count = len(transcription.split()) \n",
    "    total_errors += sum(error_counts)\n",
    "    total_words += word_count \n",
    "        \n",
    "    print(error_counts, word_count)     #you'll need to accumulate these to produce an overall Word Error Rate\n",
    "\n",
    "total_wer = total_errors / total_words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('word sil wfst with beam size 70.')\n",
    "print('num states: {}, num arcs: {}'.format(*compute_states_arcs(word_sil_wfst)))\n",
    "print('total backtrace time: {}'.format(total_backtrace_time))\n",
    "print('total decode time: {}'.format(total_decode_time))\n",
    "print('total forward computations: {}'.format(total_computations))\n",
    "print('total word error rate: {}'.format(total_wer)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "word sil wfst with beam width 0.1.\n",
    "num states: 166, num arcs: 330\n",
    "total backtrace time: 0.12229657173156738\n",
    "total decode time: 118.51288843154907\n",
    "total forward computations: 2015340\n",
    "total word error rate: 1.1092851273623665 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = word_sil_wfst \n",
    "f.set_input_symbols(state_sil_table) \n",
    "f.set_output_symbols(word_table) \n",
    "\n",
    "total_decode_time = 0 \n",
    "total_backtrace_time = 0 \n",
    "total_errors = 0 \n",
    "total_words = 0 \n",
    "total_computations = 0 \n",
    "\n",
    "\n",
    "for wav_file in glob.glob('/group/teaching/asr/labs/recordings/*.wav'):    # replace path if using your own\n",
    "                                                                           # audio files\n",
    "    \n",
    "    decoder = MyViterbiDecoder(f, wav_file, beam_width=0.01) \n",
    "    # decoder = MyViterbiDecoder(fdet, wav_file)\n",
    "    \n",
    "    decode_start_time = time.time()\n",
    "    computations = decoder.decode()\n",
    "    decode_end_time = time.time()\n",
    "    decode_time = decode_end_time - decode_start_time\n",
    "    total_decode_time += decode_time \n",
    "    print(decode_time) \n",
    "    total_computations += computations\n",
    "    print(computations) \n",
    "    # (state_path, words) = decoder.backtrace()  # you'll need to modify the backtrace() from Lab 4\n",
    "                                               # to return the words along the best path\n",
    "    backtrace_start_time = time.time()\n",
    "    # (state_path, phones) = decoder.backtrace()\n",
    "    (statee_path, words) = decoder.backtrace()\n",
    "    backtrace_end_time = time.time()\n",
    "    backtrace_time = backtrace_end_time - backtrace_start_time \n",
    "    total_backtrace_time += backtrace_time \n",
    "    print(backtrace_time) \n",
    "    print(words)\n",
    "    transcription = read_transcription(wav_file)\n",
    "    print(transcription)\n",
    "    error_counts = wer.compute_alignment_errors(transcription, words)\n",
    "    word_count = len(transcription.split()) \n",
    "    total_errors += sum(error_counts)\n",
    "    total_words += word_count \n",
    "        \n",
    "    print(error_counts, word_count)     #you'll need to accumulate these to produce an overall Word Error Rate\n",
    "\n",
    "total_wer = total_errors / total_words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('word sil wfst with beam width 0.01.')\n",
    "print('num states: {}, num arcs: {}'.format(*compute_states_arcs(word_sil_wfst)))\n",
    "print('total backtrace time: {}'.format(total_backtrace_time))\n",
    "print('total decode time: {}'.format(total_decode_time))\n",
    "print('total forward computations: {}'.format(total_computations))\n",
    "print('total word error rate: {}'.format(total_wer)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('word sil wfst with beam width 1e-6.')\n",
    "print('num states: {}, num arcs: {}'.format(*compute_states_arcs(word_sil_wfst)))\n",
    "print('total backtrace time: {}'.format(total_backtrace_time))\n",
    "print('total decode time: {}'.format(total_decode_time))\n",
    "print('total forward computations: {}'.format(total_computations))\n",
    "print('total word error rate: {}'.format(total_wer)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('word sil wfst with beam width 1e-8.')\n",
    "print('num states: {}, num arcs: {}'.format(*compute_states_arcs(word_sil_wfst)))\n",
    "print('total backtrace time: {}'.format(total_backtrace_time))\n",
    "print('total decode time: {}'.format(total_decode_time))\n",
    "print('total forward computations: {}'.format(total_computations))\n",
    "print('total word error rate: {}'.format(total_wer)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('word sil wfst with beam width 1e-10.')\n",
    "print('num states: {}, num arcs: {}'.format(*compute_states_arcs(word_sil_wfst)))\n",
    "print('total backtrace time: {}'.format(total_backtrace_time))\n",
    "print('total decode time: {}'.format(total_decode_time))\n",
    "print('total forward computations: {}'.format(total_computations))\n",
    "print('total word error rate: {}'.format(total_wer)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = word_sil_wfst \n",
    "f.set_input_symbols(state_sil_table) \n",
    "f.set_output_symbols(word_table) \n",
    "\n",
    "total_decode_time = 0 \n",
    "total_backtrace_time = 0 \n",
    "total_errors = 0 \n",
    "total_words = 0 \n",
    "total_computations = 0 \n",
    "\n",
    "\n",
    "for wav_file in glob.glob('/group/teaching/asr/labs/recordings/*.wav'):    # replace path if using your own\n",
    "                                                                           # audio files\n",
    "    \n",
    "    decoder = MyViterbiDecoder(f, wav_file, beam_width=1e-12) \n",
    "    # decoder = MyViterbiDecoder(fdet, wav_file)\n",
    "    \n",
    "    decode_start_time = time.time()\n",
    "    computations = decoder.decode()\n",
    "    decode_end_time = time.time()\n",
    "    decode_time = decode_end_time - decode_start_time\n",
    "    total_decode_time += decode_time \n",
    "    print(decode_time) \n",
    "    total_computations += computations\n",
    "    print(computations) \n",
    "    # (state_path, words) = decoder.backtrace()  # you'll need to modify the backtrace() from Lab 4\n",
    "                                               # to return the words along the best path\n",
    "    backtrace_start_time = time.time()\n",
    "    # (state_path, phones) = decoder.backtrace()\n",
    "    (statee_path, words) = decoder.backtrace()\n",
    "    backtrace_end_time = time.time()\n",
    "    backtrace_time = backtrace_end_time - backtrace_start_time \n",
    "    total_backtrace_time += backtrace_time \n",
    "    print(backtrace_time) \n",
    "    print(words)\n",
    "    transcription = read_transcription(wav_file)\n",
    "    print(transcription)\n",
    "    error_counts = wer.compute_alignment_errors(transcription, words)\n",
    "    word_count = len(transcription.split()) \n",
    "    total_errors += sum(error_counts)\n",
    "    total_words += word_count \n",
    "        \n",
    "    print(error_counts, word_count)     #you'll need to accumulate these to produce an overall Word Error Rate\n",
    "\n",
    "total_wer = total_errors / total_words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('word sil wfst with beam width 1e-12.')\n",
    "print('num states: {}, num arcs: {}'.format(*compute_states_arcs(word_sil_wfst)))\n",
    "print('total backtrace time: {}'.format(total_backtrace_time))\n",
    "print('total decode time: {}'.format(total_decode_time))\n",
    "print('total forward computations: {}'.format(total_computations))\n",
    "print('total word error rate: {}'.format(total_wer)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.1,0.01, 0.001, 0.0001, 0.00001, 1e-6 \n",
    "print(np.array([118.51, 131.78, 149.83, 172.63, 188.85,  208.86, 261.79, 300.51, 345.89]) / 1387.72)\n",
    "print(np.array([2015340, 2641318, 3196708, 3726574, 4328928, 5061720, 6840482, 8167990, 9714586]) / 47778204) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('word sil wfst with beam width 0.0001.')\n",
    "print('num states: {}, num arcs: {}'.format(*compute_states_arcs(word_sil_wfst)))\n",
    "print('total backtrace time: {}'.format(total_backtrace_time))\n",
    "print('total decode time: {}'.format(total_decode_time))\n",
    "print('total forward computations: {}'.format(total_computations))\n",
    "print('total word error rate: {}'.format(total_wer)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('word sil wfst with beam width 0.00001.')\n",
    "print('num states: {}, num arcs: {}'.format(*compute_states_arcs(word_sil_wfst)))\n",
    "print('total backtrace time: {}'.format(total_backtrace_time))\n",
    "print('total decode time: {}'.format(total_decode_time))\n",
    "print('total forward computations: {}'.format(total_computations))\n",
    "print('total word error rate: {}'.format(total_wer)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = tree_sequence_wfst \n",
    "f.set_input_symbols(state_sil_table) \n",
    "f.set_output_symbols(word_table) \n",
    "\n",
    "total_decode_time = 0 \n",
    "total_backtrace_time = 0 \n",
    "total_errors = 0 \n",
    "total_words = 0 \n",
    "total_computations = 0 \n",
    "\n",
    "\n",
    "for wav_file in glob.glob('/group/teaching/asr/labs/recordings/*.wav'):    # replace path if using your own\n",
    "                                                                           # audio files\n",
    "    \n",
    "    decoder = MyViterbiDecoder(f, wav_file) \n",
    "    # decoder = MyViterbiDecoder(fdet, wav_file)\n",
    "    \n",
    "    decode_start_time = time.time()\n",
    "    computations = decoder.decode()\n",
    "    decode_end_time = time.time()\n",
    "    decode_time = decode_end_time - decode_start_time\n",
    "    total_decode_time += decode_time \n",
    "    print(decode_time) \n",
    "    total_computations += computations\n",
    "    print(computations) \n",
    "    # (state_path, words) = decoder.backtrace()  # you'll need to modify the backtrace() from Lab 4\n",
    "                                               # to return the words along the best path\n",
    "    backtrace_start_time = time.time()\n",
    "    # (state_path, phones) = decoder.backtrace()\n",
    "    (statee_path, words) = decoder.backtrace()\n",
    "    backtrace_end_time = time.time()\n",
    "    backtrace_time = backtrace_end_time - backtrace_start_time \n",
    "    total_backtrace_time += backtrace_time \n",
    "    print(backtrace_time) \n",
    "    print(words)\n",
    "    transcription = read_transcription(wav_file)\n",
    "    print(transcription)\n",
    "    error_counts = wer.compute_alignment_errors(transcription, words)\n",
    "    word_count = len(transcription.split()) \n",
    "    total_errors += sum(error_counts)\n",
    "    total_words += word_count \n",
    "        \n",
    "    print(error_counts, word_count)     #you'll need to accumulate these to produce an overall Word Error Rate\n",
    "\n",
    "total_wer = total_errors / total_words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('tree sequence wfst')\n",
    "print('num states: {}, num arcs: {}'.format(*compute_states_arcs(tree_sequence_wfst)))\n",
    "print('total backtrace time: {}'.format(total_backtrace_time))\n",
    "print('total decode time: {}'.format(total_decode_time))\n",
    "print('total forward computations: {}'.format(total_computations))\n",
    "print('total word error rate: {}'.format(total_wer)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = bigram_sil_wfst \n",
    "f.set_input_symbols(state_sil_table) \n",
    "f.set_output_symbols(word_table) \n",
    "\n",
    "total_decode_time = 0 \n",
    "total_backtrace_time = 0 \n",
    "total_errors = 0 \n",
    "total_words = 0 \n",
    "total_computations = 0 \n",
    "\n",
    "\n",
    "for wav_file in glob.glob('/group/teaching/asr/labs/recordings/*.wav'):    # replace path if using your own\n",
    "                                                                           # audio files\n",
    "    \n",
    "    decoder = MyViterbiDecoder(f, wav_file) \n",
    "    # decoder = MyViterbiDecoder(fdet, wav_file)\n",
    "    \n",
    "    decode_start_time = time.time()\n",
    "    computations = decoder.decode()\n",
    "    decode_end_time = time.time()\n",
    "    decode_time = decode_end_time - decode_start_time\n",
    "    total_decode_time += decode_time \n",
    "    print(decode_time) \n",
    "    total_computations += computations\n",
    "    print(computations) \n",
    "    # (state_path, words) = decoder.backtrace()  # you'll need to modify the backtrace() from Lab 4\n",
    "                                               # to return the words along the best path\n",
    "    backtrace_start_time = time.time()\n",
    "    # (state_path, phones) = decoder.backtrace()\n",
    "    (statee_path, words) = decoder.backtrace()\n",
    "    backtrace_end_time = time.time()\n",
    "    backtrace_time = backtrace_end_time - backtrace_start_time \n",
    "    total_backtrace_time += backtrace_time \n",
    "    print(backtrace_time) \n",
    "    print(words)\n",
    "    transcription = read_transcription(wav_file)\n",
    "    print(transcription)\n",
    "    error_counts = wer.compute_alignment_errors(transcription, words)\n",
    "    word_count = len(transcription.split()) \n",
    "    total_errors += sum(error_counts)\n",
    "    total_words += word_count \n",
    "        \n",
    "    print(error_counts, word_count)     #you'll need to accumulate these to produce an overall Word Error Rate\n",
    "\n",
    "total_wer = total_errors / total_words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('bigram sil wfst')\n",
    "print('num state: {}, num arcs: {}'.format(*compute_states_arcs(sequence_sil_wfst)))\n",
    "print('total backtrace time: {}'.format(total_backtrace_time))\n",
    "print('total decode time: {}'.format(total_decode_time))\n",
    "print('total forward computations: {}'.format(total_computations))\n",
    "print('total word error rate: {}'.format(total_wer)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_states_arcs(bigram_sil_wfst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = sequence_sil_wfst \n",
    "f.set_input_symbols(state_sil_table) \n",
    "f.set_output_symbols(word_table) \n",
    "\n",
    "total_decode_time = 0 \n",
    "total_backtrace_time = 0 \n",
    "total_errors = 0 \n",
    "total_words = 0 \n",
    "total_computations = 0 \n",
    "\n",
    "\n",
    "for wav_file in glob.glob('/group/teaching/asr/labs/recordings/*.wav'):    # replace path if using your own\n",
    "                                                                           # audio files\n",
    "    \n",
    "    decoder = MyViterbiDecoder(f, wav_file) \n",
    "    # decoder = MyViterbiDecoder(fdet, wav_file)\n",
    "    \n",
    "    decode_start_time = time.time()\n",
    "    computations = decoder.decode()\n",
    "    decode_end_time = time.time()\n",
    "    decode_time = decode_end_time - decode_start_time\n",
    "    total_decode_time += decode_time \n",
    "    print(decode_time) \n",
    "    total_computations += computations\n",
    "    print(computations) \n",
    "    # (state_path, words) = decoder.backtrace()  # you'll need to modify the backtrace() from Lab 4\n",
    "                                               # to return the words along the best path\n",
    "    backtrace_start_time = time.time()\n",
    "    # (state_path, phones) = decoder.backtrace()\n",
    "    (statee_path, words) = decoder.backtrace()\n",
    "    backtrace_end_time = time.time()\n",
    "    backtrace_time = backtrace_end_time - backtrace_start_time \n",
    "    total_backtrace_time += backtrace_time \n",
    "    print(backtrace_time) \n",
    "    print(words)\n",
    "    transcription = read_transcription(wav_file)\n",
    "    print(transcription)\n",
    "    error_counts = wer.compute_alignment_errors(transcription, words)\n",
    "    word_count = len(transcription.split()) \n",
    "    total_errors += sum(error_counts)\n",
    "    total_words += word_count \n",
    "        \n",
    "    print(error_counts, word_count)     #you'll need to accumulate these to produce an overall Word Error Rate\n",
    "\n",
    "total_wer = total_errors / total_words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('''sequence sil wfst, the transition probability from the final phone state of the word to the silence \n",
    "state: 0.9 * 0.5, to the final state of the word: 0.9 * 0.5. ''')\n",
    "print('num states: {}, num arcs: {}'.format(*compute_states_arcs(sequence_sil_wfst)))\n",
    "print('total backtrace time: {}'.format(total_backtrace_time))\n",
    "print('total decode time: {}'.format(total_decode_time))\n",
    "print('total forward computations: {}'.format(total_computations))\n",
    "print('total word error rate: {}'.format(total_wer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sequence sil wfst, the transition probability from the final phone state of the word to the silence \n",
    "state: 0.9 * 0.5, to the final state of the word: 0.9 * 0.5. \n",
    "num states: 166, num arcs: 340\n",
    "total backtrace time: 0.1382451057434082\n",
    "total decode time: 1413.3285076618195\n",
    "total forward computations: 49310994\n",
    "total word error rate: 0.7140509449465899 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = sequence_sil_wfst \n",
    "f.set_input_symbols(state_sil_table) \n",
    "f.set_output_symbols(word_table) \n",
    "\n",
    "total_decode_time = 0 \n",
    "total_backtrace_time = 0 \n",
    "total_errors = 0 \n",
    "total_words = 0 \n",
    "total_computations = 0 \n",
    "\n",
    "\n",
    "for wav_file in glob.glob('/group/teaching/asr/labs/recordings/*.wav'):    # replace path if using your own\n",
    "                                                                           # audio files\n",
    "    \n",
    "    decoder = MyViterbiDecoder(f, wav_file) \n",
    "    # decoder = MyViterbiDecoder(fdet, wav_file)\n",
    "    \n",
    "    decode_start_time = time.time()\n",
    "    computations = decoder.decode()\n",
    "    decode_end_time = time.time()\n",
    "    decode_time = decode_end_time - decode_start_time\n",
    "    total_decode_time += decode_time \n",
    "    print(decode_time) \n",
    "    total_computations += computations\n",
    "    print(computations) \n",
    "    # (state_path, words) = decoder.backtrace()  # you'll need to modify the backtrace() from Lab 4\n",
    "                                               # to return the words along the best path\n",
    "    backtrace_start_time = time.time()\n",
    "    # (state_path, phones) = decoder.backtrace()\n",
    "    (statee_path, words) = decoder.backtrace()\n",
    "    backtrace_end_time = time.time()\n",
    "    backtrace_time = backtrace_end_time - backtrace_start_time \n",
    "    total_backtrace_time += backtrace_time \n",
    "    print(backtrace_time)\n",
    "    print(words)\n",
    "    transcription = read_transcription(wav_file)\n",
    "    print(transcription)\n",
    "    error_counts = wer.compute_alignment_errors(transcription, words)\n",
    "    word_count = len(transcription.split()) \n",
    "    total_errors += sum(error_counts)\n",
    "    total_words += word_count \n",
    "        \n",
    "    print(error_counts, word_count)     #you'll need to accumulate these to produce an overall Word Error Rate\n",
    "\n",
    "total_wer = total_errors / total_words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('''sequence sil wfst, the transition probability from the final phone state of the word to the silence \n",
    "state: 0.9 * 0.8, to the final word state: 0.9 * 0.2''')\n",
    "print('num state: {}, num arcs: {}'.format(*compute_states_arcs(sequence_sil_wfst)))\n",
    "print('total backtrace time: {}'.format(total_backtrace_time))\n",
    "print('total decode time: {}'.format(total_decode_time))\n",
    "print('total forward computations: {}'.format(total_computations))\n",
    "print('total word error rate: {}'.format(total_wer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sequence sil wfst, the transition probability from the final phone state of the word to the silence \n",
    "state: 0.9 * 0.8, to the final word state: 0.9 * 0.2\n",
    "num state: 166, num arcs: 340\n",
    "total backtrace time: 0.1392526626586914\n",
    "total decode time: 1413.9680876731873\n",
    "total forward computations: 49310994\n",
    "total word error rate: 0.6972062448644207 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import wer\n",
    "import observation_model\n",
    "import openfst_python as fst\n",
    "import time\n",
    "\n",
    "# ... (add your code to create WFSTs and Viterbi Decoder)\n",
    "\n",
    "def read_transcription(wav_file):\n",
    "    \"\"\"\n",
    "    Get the transcription corresponding to wav_file.\n",
    "    \"\"\"\n",
    "    \n",
    "    transcription_file = os.path.splitext(wav_file)[0] + '.txt'\n",
    "    \n",
    "    with open(transcription_file, 'r') as f:\n",
    "        transcription = f.readline().strip()\n",
    "    \n",
    "    return transcription\n",
    "\n",
    " \n",
    "# f = create_wfst()\n",
    "f = create_wfst\n",
    "f.set_input_symbols(state_table)\n",
    "f.set_output_symbols(word_table)\n",
    "fdet = fst.determinize(f)\n",
    "fmin = fdet.minimize()\n",
    "\n",
    "total_decode_time = 0 \n",
    "total_backtrace_time = 0 \n",
    "total_errors = 0 \n",
    "total_words = 0 \n",
    "\n",
    "\n",
    "for wav_file in glob.glob('/group/teaching/asr/labs/recordings/*.wav'):    # replace path if using your own\n",
    "                                                                           # audio files\n",
    "    decoder = ViterbiDecoder()\n",
    "    decoder = MyViterbiDecoder(f, wav_file)\n",
    "    # decoder = MyViterbiDecoder(fdet, wav_file)\n",
    "    \n",
    "    decode_start_time = time.time()\n",
    "    decoder.decode()\n",
    "    decode_end_time = time.time()\n",
    "    decode_time = decode_end_time - decode_start_time\n",
    "    total_decode_time += decode_time \n",
    "    print(decode_time)\n",
    "    # (state_path, words) = decoder.backtrace()  # you'll need to modify the backtrace() from Lab 4\n",
    "                                               # to return the words along the best path\n",
    "    backtrace_start_time = time.time()\n",
    "    (state_path, words) = decoder.backtrace()\n",
    "    backtrace_end_time = time.time()\n",
    "    backtrace_time = backtrace_end_time - backtrace_start_time \n",
    "    total_backtrace_time += backtrace_time \n",
    "    print(backtrace_time)  \n",
    "    \n",
    "    \n",
    "    print(words)\n",
    "    transcription = read_transcription(wav_file)\n",
    "    # print(transcription)\n",
    "    error_counts = wer.compute_alignment_errors(transcription, words)\n",
    "    word_count = len(transcription.split()) \n",
    "    total_errors += sum(error_counts)\n",
    "    total_words += word_count \n",
    "        \n",
    "    print(error_counts, word_count)     #you'll need to accumulate these to produce an overall Word Error Rate\n",
    "\n",
    "total_wer = total_errors / total_words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fdet\n",
    "from subprocess import check_call\n",
    "from IPython.display import Image\n",
    "f.draw('tmp.dot', portrait=True)\n",
    "# fdet.draw('tmp.dot', portrait=True)\n",
    "check_call(['dot','-Tpng','-Gdpi=200','tmp.dot','-o','tmp.png'])\n",
    "Image(filename='tmp.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
